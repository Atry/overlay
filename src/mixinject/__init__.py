"""
mixinject: A dependency injection framework with pytest-fixture-like semantics.

## Core Design Principle: Explicit Decorator Marking

All injectable definitions MUST be explicitly marked with one of these decorators:
- @resource: Creates a base resource that can be modified by patches
- @patch: Provides a single modification to an existing resource
- @patches: Provides multiple modifications to an existing resource
- @aggregator: Defines custom aggregation strategy for patches

Bare callables (functions without decorators) are NOT automatically injected.
This explicit-only design makes dependency injection predictable and self-documenting.

## Example

```python
from mixinject import resource, patch, resolve

# ✓ CORRECT: Explicitly decorated
@resource
def greeting() -> str:
    return "Hello"

@patch
def greeting() -> Callable[[str], str]:
    return lambda s: s + "!"

# ✗ INCORRECT: Bare callable (will be ignored)
def ignored_function() -> str:
    return "This won't be injected"

root = resolve(...)
root.greeting  # "Hello!"
root.ignored_function  # AttributeError: 'CachedProxy' object has no attribute 'ignored_function'
```
"""

import importlib
import importlib.util
import pkgutil
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from functools import reduce
from inspect import signature
from types import ModuleType
from typing import (
    Any,
    Callable,
    Collection,
    Hashable,
    Generic,
    Iterable,
    Iterator,
    Mapping,
    MutableMapping,
    NewType,
    Self,
    TypeAlias,
    TypeVar,
    cast,
    override,
)
from weakref import WeakValueDictionary

Resource = NewType("Resource", object)


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class Proxy(Mapping[str, "Node"], ABC):
    """
    A Proxy represents resources available via attributes or keys.
    """

    mixins: frozenset["Mixin"]

    def __getitem__(self, key: str) -> "Node":
        def generate_resource() -> Iterator[Builder | Patcher]:
            for mixins in self.mixins:
                try:
                    factory_or_patch = mixins[key]
                except KeyError:
                    continue
                yield factory_or_patch(self)

        return _evaluate_resource(resource_generator=generate_resource)

    def __getattr__(self, key: str) -> "Node":
        try:
            return self[key]
        except KeyError as e:
            raise AttributeError(name=key, obj=self) from e

    def __iter__(self) -> Iterator[str]:
        visited: set[str] = set()
        for mixins in self.mixins:
            for key in mixins:
                if key not in visited:
                    visited.add(key)
                    yield key

    def __len__(self) -> int:
        keys: set[str] = set()
        for mixins in self.mixins:
            keys.update(mixins)
        return len(keys)

    def __call__(self, **kwargs: object) -> Self:
        return type(self)(mixins=self.mixins | {KeywordArgumentMixin(kwargs=kwargs)})


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class CachedProxy(Proxy):
    _cache: MutableMapping[str, "Node"] = field(
        default_factory=dict, init=False, repr=False, compare=False
    )

    @override
    def __getitem__(self, key: str) -> "Node":
        if key not in self._cache:
            value = Proxy.__getitem__(self, key)
            self._cache[key] = value
            return value
        else:
            return self._cache[key]


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class WeakCachedScope(CachedProxy):
    _cache: MutableMapping[str, "Node"] = field(
        default_factory=WeakValueDictionary, init=False, repr=False, compare=False
    )


def _calculate_most_derived_class(first: type, *rest: type) -> type:
    """Calculate the most derived class."""

    candidates = (first,)
    for new_candidate in rest:
        if any(issubclass(candidate, new_candidate) for candidate in candidates):
            continue
        else:
            candidates = (
                *(
                    candidate
                    for candidate in candidates
                    if not issubclass(new_candidate, candidate)
                ),
                new_candidate,
            )

    match candidates:
        case (winner,):
            return winner
        case _:
            raise TypeError(
                "class conflict: "
                "the class of a derived class "
                "must be a (non-strict) subclass "
                "of the classes of all its bases"
            )


def merge_proxies(proxies: Iterable[Proxy]) -> Proxy:
    """
    Merge multiple proxies into a single proxy.
    The resulting proxy's class is the most derived class among the input proxies.
    The resulting proxy's mixins are the union of all input proxies' mixins.
    """
    proxies_list = list(proxies)
    if not proxies_list:
        raise ValueError("No proxies to merge")

    winner_class = _calculate_most_derived_class(*(type(p) for p in proxies_list))

    def generate_all_mixins() -> Iterator[Mixin]:
        for p in proxies_list:
            yield from p.mixins

    return winner_class(mixins=frozenset(generate_all_mixins()))


LexicalScope: TypeAlias = Callable[[], Iterator[Proxy]]
"""
A generator function that yields proxies representing the lexical scope, starting from the innermost proxy to the outermost proxy.
"""


def loop_up(lexical_scope: LexicalScope, name: str) -> "Node":
    """
    Look up a resource by name in the lexical scope chain.
    Returns the first found value, searching from innermost to outermost scope.
    """
    for proxy in lexical_scope():
        try:
            return proxy[name]
        except KeyError:
            continue
    raise KeyError(name)


Node: TypeAlias = Resource | Proxy
TPatcher_co = TypeVar("TPatcher_co", covariant=True)
TPatcher_contra = TypeVar("TPatcher_contra", contravariant=True)
TResult_co = TypeVar("TResult_co", covariant=True)


class Builder(Generic[TPatcher_contra, TResult_co], ABC):
    @abstractmethod
    def create(self, patches: Iterator[TPatcher_contra]) -> TResult_co: ...


class Patcher(Iterable[TPatcher_co], ABC):
    """
    An Patcher provides extra data to be applied to a Node created by a ``Builder``.
    """


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class FunctionPatch(Patcher[TPatcher_co]):
    patch_generator: Callable[[], Iterator[TPatcher_co]]

    def __iter__(self) -> Iterator[TPatcher_co]:
        return self.patch_generator()


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class FunctionBuilder(Builder[TPatcher_contra, TResult_co]):
    """Builder that applies custom aggregation function to patches."""

    aggregation_function: Callable[[Iterator[TPatcher_contra]], TResult_co]

    @override
    def create(self, patches: Iterator[TPatcher_contra]) -> TResult_co:
        return self.aggregation_function(patches)


TResult = TypeVar("TResult")
TProxy = TypeVar("TProxy", bound=Proxy)


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class EndoBuilder(Generic[TResult], Builder[Callable[[TResult], TResult], TResult]):
    """Builder that applies patches as endofunctions via reduce."""

    base_value: TResult

    @override
    def create(self, patches: Iterator[Callable[[TResult], TResult]]) -> TResult:
        return reduce(lambda acc, endo: endo(acc), patches, self.base_value)


class Mixin(Mapping[str, Callable[[Proxy], Builder | Patcher]], Hashable, ABC):
    """
    Abstract base class for mixins.
    Mixins are mappings from resource names to factory functions.
    They must compare by identity to allow storage in sets.
    """

    def __hash__(self) -> int:
        return hash(id(self))

    def __eq__(self, other: object) -> bool:
        return self is other


def _evaluate_resource(
    resource_generator: Callable[[], Iterator[Builder | Patcher]],
) -> Node:
    """
    Evaluate a resource by selecting a Builder and applying Patches.

    Algorithm for selecting the Builder:
    1. If there is exactly one item that is a Builder but NOT a Patch (pure Builder),
       it is selected as the Builder. All other items (including those that are both)
       are treated as Patches.
    2. If there are multiple pure Builders, a ValueError is raised.
    3. If there are no pure Builders, but there are items that are both Builder and Patch:
       One is arbitrarily selected as the Builder, and the rest are treated as Patches.
       (This assumes the semantics of these items satisfy commutativity).
    4. If there are no Builders (pure or dual), a NotImplementedError is raised.
    """
    items = list(resource_generator())
    if not items:
        raise KeyError("No resource found")

    pure_builders: list[Builder] = []
    pure_patches: list[Patcher] = []
    dual_items: list[Builder] = []  # Typed as Builder, but are also Patch

    for item in items:
        is_builder = isinstance(item, Builder)
        is_patch = isinstance(item, Patcher)

        if is_builder and not is_patch:
            pure_builders.append(item)
        elif is_builder and is_patch:
            dual_items.append(item)  # type: ignore
        elif is_patch:
            pure_patches.append(item)

    selected_builder: Builder
    patches_to_apply: list[Patcher]

    if len(pure_builders) == 1:
        selected_builder = pure_builders[0]
        # Dual items are treated as patches here
        patches_to_apply = cast(list[Patcher], dual_items) + pure_patches
    elif len(pure_builders) > 1:
        raise ValueError("Multiple Factory definitions provided")
    else:
        # No pure builders
        if not dual_items:
            raise NotImplementedError("No Factory definition provided")

        # Pick one dual item as builder
        selected_builder = dual_items[0]
        # Remaining dual items are patches
        patches_to_apply = cast(list[Patcher], dual_items[1:]) + pure_patches

    # Flatten the patches
    flat_patches = (
        patch_content
        for patch_container in patches_to_apply
        for patch_content in patch_container
    )

    return selected_builder.create(flat_patches)


class Definition(ABC):
    @abstractmethod
    def bind_lexical_scope(
        self, outer_lexical_scope: LexicalScope, resource_name: str, /
    ) -> Callable[[Proxy], Builder | Patcher]: ...


class BuilderDefinition(Definition, Generic[TPatcher_contra, TResult_co]):
    @abstractmethod
    def bind_lexical_scope(
        self, outer_lexical_scope: LexicalScope, resource_name: str, /
    ) -> Callable[[Proxy], Builder]: ...


class PatcherDefinition(Definition, Generic[TPatcher_co]):
    @abstractmethod
    def bind_lexical_scope(
        self, outer_lexical_scope: LexicalScope, resource_name: str, /
    ) -> Callable[[Proxy], Patcher]: ...


def _resolve_dependencies(
    function: Callable[..., Any],
    resource_name: str,
    outer_lexical_scope: LexicalScope,
    proxy: Proxy,
) -> Mapping[str, Any]:
    """
    Resolve dependencies for a callable based on its parameter names.

    Special case: when param_name == resource_name, uses outer lexical scope (not current proxy).
    This implements pytest-fixture-like same-name dependency injection semantics.

    Normal case: param_name != resource_name looks in current proxy first, then falls back to outer lexical scope.
    """

    def resolve_param(param_name: str) -> Any:
        """
        Resolve a single parameter by name.
        1. If param_name == resource_name, look up in outer lexical scope to avoid self-dependency, mimicking pytest fixture behavior.
        2. Otherwise, try to get from current proxy, falling back to outer lexical scope if not found.
        """
        if param_name == resource_name:
            # pytest fixture-like behavior to not recursively depend on itself
            return loop_up(outer_lexical_scope, param_name)
        try:
            return proxy[param_name]
        except KeyError:
            return loop_up(outer_lexical_scope, param_name)

    sig = signature(function)
    return {param_name: resolve_param(param_name) for param_name in sig.parameters}


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class AggregatorDefinition(BuilderDefinition[TPatcher_contra, TResult_co]):
    """Definition for aggregator decorator."""

    function: Callable[..., Callable[[Iterator[TPatcher_contra]], TResult_co]]

    @override
    def bind_lexical_scope(
        self, outer_lexical_scope: LexicalScope, resource_name: str, /
    ) -> Callable[[Proxy], Builder[TPatcher_contra, TResult_co]]:
        def bind_proxy(proxy: Proxy) -> Builder[TPatcher_contra, TResult_co]:
            dependencies = _resolve_dependencies(
                self.function, resource_name, outer_lexical_scope, proxy
            )
            return FunctionBuilder(aggregation_function=self.function(**dependencies))

        return bind_proxy


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class ResourceDefinition(
    Generic[TResult], BuilderDefinition[Callable[[TResult], TResult], TResult]
):
    """Definition for resource decorator."""

    function: Callable[..., TResult]

    @override
    def bind_lexical_scope(
        self, outer_lexical_scope: LexicalScope, resource_name: str, /
    ) -> Callable[[Proxy], Builder[Callable[[TResult], TResult], TResult]]:
        def bind_proxy(proxy: Proxy) -> Builder[Callable[[TResult], TResult], TResult]:
            resolved_args = _resolve_dependencies(
                self.function, resource_name, outer_lexical_scope, proxy
            )
            base_value = self.function(**resolved_args)
            return EndoBuilder(base_value=base_value)

        return bind_proxy


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class SinglePatchDefinition(PatcherDefinition[TPatcher_co]):
    """Definition for patch decorator (single patch)."""

    function: Callable[..., TPatcher_co]

    @override
    def bind_lexical_scope(
        self, outer_lexical_scope: LexicalScope, resource_name: str, /
    ) -> Callable[[Proxy], Patcher[TPatcher_co]]:
        def bind_proxy(proxy: Proxy) -> Patcher[TPatcher_co]:
            def patch_generator() -> Iterator[TPatcher_co]:
                resolved_args = _resolve_dependencies(
                    self.function, resource_name, outer_lexical_scope, proxy
                )
                yield self.function(**resolved_args)

            return FunctionPatch(patch_generator=patch_generator)

        return bind_proxy


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class MultiplePatchDefinition(PatcherDefinition[TPatcher_co]):
    """Definition for patches decorator (multiple patches)."""

    function: Callable[..., Collection[TPatcher_co]]

    @override
    def bind_lexical_scope(
        self, outer_lexical_scope: LexicalScope, resource_name: str, /
    ) -> Callable[[Proxy], Patcher[TPatcher_co]]:
        def bind_proxy(proxy: Proxy) -> Patcher[TPatcher_co]:
            def patch_generator() -> Iterator[TPatcher_co]:
                resolved_args = _resolve_dependencies(
                    self.function, resource_name, outer_lexical_scope, proxy
                )
                yield from self.function(**resolved_args)

            return FunctionPatch(patch_generator=patch_generator)

        return bind_proxy


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class ScopeDual(Builder[Proxy, Proxy], Patcher[Proxy]):
    definitions: Mapping[str, Definition]
    lexical_scope: LexicalScope
    proxy_class: type[Proxy]

    def own_proxy(self):
        return self.proxy_class(
            mixins=frozenset(
                (
                    BoundMixin(
                        lexical_scope=self.lexical_scope, definitions=self.definitions
                    ),
                )
            )
        )

    @override
    def create(self, patches: Iterator[Proxy]) -> Proxy:
        def all_proxies():
            yield self.own_proxy()
            yield from patches

        return merge_proxies(all_proxies())

    @override
    def __iter__(self) -> Iterator[Proxy]:
        yield self.own_proxy()


@dataclass(frozen=True, kw_only=True, slots=True, weakref_slot=True)
class ScopeDefinition(BuilderDefinition[Proxy, Proxy], PatcherDefinition[Proxy]):
    """Definition that creates a Proxy from nested ScopeDefinition (lazy evaluation)."""

    definitions: Mapping[str, Definition]
    proxy_class: type[Proxy]

    @override
    def bind_lexical_scope(
        self, outer_lexical_scope: LexicalScope, resource_name: str, /
    ) -> Callable[[Proxy], ScopeDual]:
        def bind_proxy(proxy: Proxy) -> ScopeDual:
            def inner_lexical_scope() -> Iterator[Proxy]:
                yield proxy
                yield from outer_lexical_scope()

            return ScopeDual(
                definitions=self.definitions,
                lexical_scope=inner_lexical_scope,
                proxy_class=self.proxy_class,
            )

        return bind_proxy


T = TypeVar("T")


@dataclass(frozen=True, kw_only=True)
class ObjectMapping(Mapping[str, Definition], Generic[T]):
    """
    A lazy mapping that parses definitions from an object's attributes on access.
    Implements call-by-name semantics using dir() and getattr().
    """

    underlying: T

    def __getitem__(self, key: str) -> Definition:
        try:
            val = getattr(self.underlying, key)
        except AttributeError as e:
            raise KeyError(key) from e

        if isinstance(val, Definition):
            return val
        raise KeyError(key)

    def __iter__(self) -> Iterator[str]:
        for name in dir(self.underlying):
            try:
                val = getattr(self.underlying, name)
            except AttributeError:
                continue
            if isinstance(val, Definition):
                yield name

    def __len__(self) -> int:
        return sum(1 for _ in self)


@dataclass(frozen=True, kw_only=True)
class PackageMapping(ObjectMapping[ModuleType]):
    """A lazy mapping that discovers submodules via pkgutil and imports them on access."""

    get_module_proxy_class: Callable[[ModuleType], type[Proxy]]

    @override
    def __getitem__(self, key: str) -> Definition:
        # 1. Try to get attribute from module (using super - finds Definition)
        try:
            return super().__getitem__(key)
        except KeyError:
            pass

        # 2. Try to find in submodules (if package)
        full_name = f"{self.underlying.__name__}.{key}"  # type: ignore
        try:
            spec = importlib.util.find_spec(full_name)
        except ImportError as e:
            raise KeyError(key) from e

        if spec is None:
            raise KeyError(key)

        submod = importlib.import_module(full_name)
        return ScopeDefinition(
            definitions=parse_module(
                submod, get_module_proxy_class=self.get_module_proxy_class
            ),
            proxy_class=self.get_module_proxy_class(submod),
        )

    @override
    def __iter__(self) -> Iterator[str]:
        # 1. Yield attributes that are Definitions (using super)
        yield from super().__iter__()

        # 2. Yield submodule names
        for mod_info in pkgutil.iter_modules(self.underlying.__path__):  # type: ignore
            yield mod_info.name

    @override
    def __contains__(self, key: object) -> bool:
        if super().__contains__(key):
            return True
        if not isinstance(key, str):
            return False

        full_name = f"{self.underlying.__name__}.{key}"  # type: ignore
        try:
            return importlib.util.find_spec(full_name) is not None
        except ImportError:
            return False


def parse_object(namespace: object) -> Mapping[str, Definition]:
    """
    Parses an object into a ScopeDefinition.

    Only attributes explicitly decorated with @resource, @patch, @patches, or @aggregator are included.
    Nested classes are NOT recursively parsed unless they are decorated with @scope.

    IMPORTANT: Bare callables (without decorators) are NOT automatically included.
    Users must explicitly mark all injectable definitions with appropriate decorators.
    """
    return ObjectMapping(underlying=namespace)


def scope(
    cls: type | None = None, /, *, proxy_class: type[Proxy] = CachedProxy
) -> ScopeDefinition | Callable[[type], ScopeDefinition]:
    """
    Decorator that converts a class into a ScopeProxyDefinition.
    Nested classes MUST be decorated with @scope to be included as sub-scopes.
    """

    def wrapper(c: type) -> ScopeDefinition:
        return ScopeDefinition(definitions=parse_object(c), proxy_class=proxy_class)

    if cls is None:
        return wrapper
    return wrapper(cls)


def parse_module(
    module: ModuleType, get_module_proxy_class: Callable[[ModuleType], type[Proxy]]
) -> Mapping[str, Definition]:
    """
    Parses a module into a ScopeDefinition.

    Only module-level attributes explicitly decorated with @resource, @patch, @patches, or @aggregator are included.
    Nested modules and packages are recursively parsed with lazy loading.

    IMPORTANT: Bare callables (without decorators) are NOT automatically included.
    Users must explicitly mark all injectable definitions with appropriate decorators.

    For packages (modules with __path__), uses pkgutil.iter_modules to discover submodules
    and importlib.import_module to lazily import them when accessed.
    """
    if hasattr(module, "__path__"):
        return PackageMapping(
            underlying=module, get_module_proxy_class=get_module_proxy_class
        )
    return ObjectMapping(underlying=module)


Endo = Callable[[TResult], TResult]


def aggregator(
    callable: Callable[..., Callable[[Iterator[TPatcher_contra]], TResult_co]],
) -> BuilderDefinition[TPatcher_contra, TResult_co]:
    """
    A decorator that converts a callable into a builder definition with a custom aggregation strategy for patches.

    Example:

    The following example defines an aggregator that deduplicates strings from multiple patches into a frozenset.
        # In branch0.py:

        from mixinject import aggregator
        @aggregator
        def deduplicated_tags():
            return frozenset[str]

    Now, when multiple patches provide tags, they will be aggregated into a frozenset without duplicates.

        # In branch1.py:
        @patch
        def deduplicated_tags():
            return "tag1"

        # In branch1.py:
        @resource
        def another_dependency() -> str:
            return "dependency_value"

        # In branch2.py:
        @patch
        def deduplicated_tags(another_dependency):
            return f"tag2_{another_dependency}"

        # In branch0.py:
        @aggregator
        def union_mount_point():
            return lambda mixins: CachedProxy(frozenset(mixins))

        # In branch1.py:
        @patch
        def union_mount_point():
            return KeywordArgumentMixin(kwargs={"foo": "foo"})

        # In branch2.py:
        @dataclass
        class Mixin2:
            def bar(self, foo: str) -> str:
                return f"{foo}_bar"

        # Still in branch2.py:
        @patches
        def union_mount_point():
            return resolve(Mixin2()).mixins

        # In main.py:
        import branch0
        import branch1
        import branch2
        import branch3
        root = resolve(branch0, branch1, branch2, branch3)
        root.deduplicated_tags  # frozenset(("tag1", "tag2_dependency_value"))
        root.union_mount_point.foo  # "foo"
        root.union_mount_point.bar  # "foo_bar"
        root.union_mount_point.mixins  # frozenset of all mixins from branch0, branch1, branch2, branch3


    Suppose we have an `branch3/example_module.py` defined in the same directory, and we can resolve it in `branch3/__init__.py`:

        # In __init__.py:
        @patches
        def union_mount_point(example_module: Proxy):
            return example_module.mixins
    """
    return AggregatorDefinition(function=callable)


def patch(
    callable: Callable[..., TPatcher_co],
) -> PatcherDefinition[TPatcher_co]:
    """
    A decorator that converts a callable into a patch definition.
    """
    return SinglePatchDefinition(function=callable)


def patches(
    callable: Callable[..., Collection[TPatcher_co]],
) -> PatcherDefinition[TPatcher_co]:
    """
    A decorator that converts a callable into a patch definition.
    """
    return MultiplePatchDefinition(function=callable)


def resource(
    callable: Callable[..., TResult],
) -> BuilderDefinition[Endo[TResult], TResult]:
    """
    A decorator that converts a callable into a builder definition that treats patches as endofunctions.

    It's a syntactic sugar for using ``aggregator`` with a standard endofunction application strategy.

    Example:
    The following example defines a resource that can be modified by patches.
        from mixinject import resource, patch
        @resource
        def greeting() -> str:
            return "Hello"


        @patch
        def enthusiastic_greeting() -> Endo[str]:
            return lambda original: original + "!!!"

    Alternatively, ``greeting`` can be defined with an explicit aggregator:
        from mixinject import aggregator
        @aggregator
        def greeting() -> Callable[[Iterator[Endo[str]]], str]:
            return lambda endos: reduce(
                (lambda original, endo: endo(original)),
                endos,
                "Hello"
            )
    """
    return ResourceDefinition(function=callable)


@dataclass(frozen=True, kw_only=True, slots=True, eq=False)
class BoundMixin(Mixin):
    """
    A Mixin that binds a lexical scope to a set of definitions.
    """

    lexical_scope: LexicalScope
    definitions: Mapping[str, Definition]

    def __getitem__(self, key: str, /) -> Callable[[Proxy], Builder | Patcher]:
        definition = self.definitions[key]
        return definition.bind_lexical_scope(self.lexical_scope, key)

    def __iter__(self) -> Iterator[str]:
        return iter(self.definitions)

    def __len__(self) -> int:
        return len(self.definitions)


def parse(
    namespace: object, get_module_proxy_class: Callable[[ModuleType], type[Proxy]]
) -> Mapping[str, Definition]:
    if isinstance(namespace, ModuleType):
        return parse_module(namespace, get_module_proxy_class=get_module_proxy_class)
    else:
        return parse_object(namespace)


def resolve(
    *namespaces: object,
    lexical_scope: LexicalScope = ().__iter__,
    root_proxy_class: type[TProxy] = CachedProxy,
    get_module_proxy_class: Callable[[ModuleType], type[Proxy]] = lambda _: CachedProxy,
) -> TProxy:
    """
    Resolves a Proxy from the given objects using the provided lexical scope.

    Args:
        lexical_scope: The lexical scope chain for dependency resolution.
        *namespaces: Objects (modules, classes or instances) to resolve resources from.

    Returns:
        An instance of the cls type with resolved mixins.

    Examples:
        # Use default caching
        root = resolve(().__iter__, MyNamespace)

        # Use weak reference caching
        root = resolve(().__iter__, MyNamespace, cls=WeakCachedScope)
    """

    mixins = (
        BoundMixin(
            lexical_scope=lexical_scope,
            definitions=parse(namespace, get_module_proxy_class=get_module_proxy_class),
        )
        for namespace in namespaces
    )

    return root_proxy_class(mixins=frozenset(mixins))


@dataclass(frozen=True, kw_only=True, slots=True, eq=False)
class KeywordArgumentMixin(Mixin):
    kwargs: Mapping[str, object]

    def __getitem__(self, key: str) -> Callable[[Proxy], Builder]:
        if key not in self.kwargs:
            raise KeyError(key)
        value = self.kwargs[key]

        def bind_proxy(proxy: Proxy) -> Builder[Any, Resource]:
            return EndoBuilder(base_value=cast(Resource, value))

        return bind_proxy

    def __iter__(self) -> Iterator[str]:
        return iter(self.kwargs)

    def __len__(self) -> int:
        return len(self.kwargs)
