%%
%% OOPSLA submission using ACM SIGPLAN acmart format
%%
\documentclass[manuscript,anonymous,review,10pt]{acmart}

\AtBeginDocument{%
\providecommand\BibTeX{{Bib\TeX}}}

%% Disable ACM-specific metadata for submission
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

\usepackage{mathtools}

%% Conditional citation: hide self-citations under anonymous review
\newcommand{\selfcite}[2]{%
  \if@ACM@anonymous{#2}\else{#1}\fi
}

\newcommand{\Path}{\mathtt{Path}}
\newcommand{\dom}{\mathtt{dom}}
\newcommand{\properties}{\mathtt{properties}}
\newcommand{\overlays}{\mathtt{overlays}}
\newcommand{\supers}{\mathtt{supers}}
\newcommand{\references}{\mathtt{references}}
\newcommand{\ownproperties}{\mathtt{ownproperties}}
\newcommand{\bases}{\mathtt{bases}}
\newcommand{\resolve}{\mathtt{resolve}}
\newcommand{\this}{\mathtt{this}}
\newcommand{\snoc}{\mathbin{\triangleright}}
\newcommand{\init}{\mathtt{init}}
\newcommand{\last}{\mathtt{last}}
\newcommand{\qualifiedthis}[1]{#1.\mathbf{this}}

\begin{document}

\title{Overlay-Calculus}

\author{Bo Yang}
\affiliation{%
  \institution{Figure AI Inc.}
  \city{San Jose}
  \state{California}
  \country{USA}
}
\email{yang-bo@yang-bo.com}
\thanks{This work was conducted independently prior to the author's employment at Figure AI.}

\begin{abstract}
  Just as the $\lambda$-calculus uses three primitives (abstraction,
  application, variable) as the foundation of functional programming,
  Overlay-Calculus uses three primitives (record, reference, composition)
  as the foundation of declarative programming. Unlike the $\lambda$-calculus,
  which requires first-class functions, or Turing machines, which require
  mutable state, Overlay-Calculus is purely declarative and function-free,
  yet Turing complete. A record is a set of elements---property
  definitions and composition sources---so composition is inherently
  commutative, idempotent, and associative; the linearization problem
  familiar from traditional mixin and trait systems simply does not
  arise. A straightforward translation maps the $\lambda$-calculus
  into Overlay-Calculus: function application is just symmetric
  overlay composition.
  Programs are inherently in A-normal form; unlike compiler-internal ANF
  which targets a fixed monad, Overlay-Calculus ANF supports dependency
  injection, making programs CPS-agnostic---the same code serves as either
  continuation-passing or direct-style depending on assembly.
  Records are tries and composition is trie union, so Overlay-Calculus
  is an immutable analogue of the RAM machine. These observations
  suggest Overlay-Calculus as a computational model for declarative programming,
  with applications to configuration languages,
  mixin-based object systems, composable effect systems, and modular software
  architectures.
\end{abstract}

\begin{CCSXML}
  <ccs2012>
  <concept>
  <concept_id>10003752.10010124.10010131.10010133</concept_id>
  <concept_desc>Theory of computation~Denotational semantics</concept_desc>
  <concept_significance>100</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10010124.10010125.10010128</concept_id>
  <concept_desc>Theory of computation~Object oriented constructs</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10010124.10010125.10010127</concept_id>
  <concept_desc>Theory of computation~Functional constructs</concept_desc>
  <concept_significance>300</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10010124.10010125.10010129</concept_id>
  <concept_desc>Theory of computation~Program schemes</concept_desc>
  <concept_significance>100</concept_significance>
  </concept>
  <concept>
  <concept_id>10011007.10011006.10011039</concept_id>
  <concept_desc>Software and its engineering~Formal language definitions</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10011007.10011006.10011008.10011009.10011019</concept_id>
  <concept_desc>Software and its engineering~Extensible languages</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10011007.10011006.10011008.10011009.10011011</concept_id>
  <concept_desc>Software and its engineering~Object oriented languages</concept_desc>
  <concept_significance>100</concept_significance>
  </concept>
  </ccs2012>
\end{CCSXML}

\ccsdesc[100]{Theory of computation~Denotational semantics}
\ccsdesc[500]{Theory of computation~Object oriented constructs}
\ccsdesc[300]{Theory of computation~Functional constructs}
\ccsdesc[100]{Theory of computation~Program schemes}
\ccsdesc[500]{Software and its engineering~Formal language definitions}
\ccsdesc[500]{Software and its engineering~Extensible languages}
\ccsdesc[100]{Software and its engineering~Object oriented languages}

\maketitle

\section{Introduction}
\label{sec:introduction}

Declarative and configuration languages are ubiquitous in modern software
engineering. Systems such as NixOS modules~\cite{dolstra2008nixos,nixosmodules},
Jsonnet~\cite{jsonnet}, Hydra~\cite{hydra2023}, CUE~\cite{cue2019}, Dhall~\cite{dhall2017},
Kustomize~\cite{kustomize}, and JSON Patch~\cite{rfc6902} all provide mechanisms for composing
structured data through inheritance or overlay. Among these, the NixOS
module system stands out: its recursive attribute set merging with
fixed-point semantics and deferred modules~\cite{nixosmodules} achieves
remarkable expressiveness in practice, and the mechanism has been adopted well beyond NixOS itself---Home
Manager~\cite{homemanager}, nix-darwin~\cite{nixdarwin},
disko~\cite{disko}, flake-parts~\cite{flakeparts},
dream2nix~\cite{dream2nix}, devenv~\cite{devenv},
KubeNix~\cite{kubenix}, and nixidy~\cite{nixidy} use it to manage
user environments, macOS configuration, disk partitioning, flake
structure, multi-language packaging, developer environments, and
Kubernetes clusters respectively. Yet no computational
theory explains \emph{why} this mechanism is so powerful.

The $\lambda$-calculus serves as the foundational computational model for
functional programming. No analogous calculus exists for declarative
programming. This gap matters because the two paradigms differ in
fundamental ways. Configuration languages are inherently declarative:
their values are \emph{immutable} and they have \emph{no first-class
functions}. At first glance, Turing completeness appears incompatible
with these constraints. The three classical models of computation each
violate at least one of them:

\begin{center}
  \begin{tabular}{lccc}
    \textbf{Model} & \textbf{Turing complete} & \textbf{Immutable} & \textbf{No $\lambda$} \\
    \hline
    Turing Machine     & $\checkmark$ & $\times$     & $\checkmark$ \\
    $\lambda$-calculus & $\checkmark$ & $\checkmark$ & $\times$ \\
    RAM Machine        & $\checkmark$ & $\times$     & $\checkmark$ \\
  \end{tabular}
\end{center}

\noindent
The Turing Machine and RAM Machine require mutable state;
the $\lambda$-calculus requires first-class functions.
A computational model that is Turing complete, immutable, and
function-free would sit in the empty cell of this table.
The NixOS module system already suggests that such a model exists:
its inheritance-based composition over recursive records, without
explicit functions, is expressive enough to configure entire operating
systems.

Conventionally, the value domain of configuration languages is assumed
to consist of finite, well-founded structures---initial algebras in the
sense of universal algebra. We challenge this assumption: configuration
values are better understood as lazily observable, possibly infinite
structures---in the spirit of F-coalgebras~\cite{rutten2000universal}---where
semantics is determined by the observer and a finite prefix suffices
for any finite observation. This is not merely a theoretical
distinction: the \texttt{nixpkgs} package
collection~\cite{dolstra2006purely}---over 100{,}000
packages---behaves as a lazily observed structure in practice, allowing any
single package to be evaluated without materializing the entire set.
Guided by this observation and by the NixOS module system's
recursive merging mechanism, we built the Overlay
language\selfcite{~\cite{mixin2025}}{~(included as supplementary
material)}---a declarative programming language with only three
constructs (record literals, references, and composition) and no
functions or let-bindings.

In developing real programs in the Overlay language---Church-encoded
data types (Appendix~\ref{app:church}), an Expression Problem solution
(Section~\ref{sec:expression-problem}), trie-based random-access memory
(Appendix~\ref{app:trie}), and continuation patterns
(Section~\ref{sec:cps-agnostic})---we discovered that several
long-standing problems in programming language theory do not arise.
The linearization problem that has plagued mixin-based
systems~\cite{bracha1990mixin,c3linearization} does not exist---not
because it is resolved, but because the three primitives make it
structurally impossible (Section~\ref{sec:overlay-trees}).
Self-reference naturally resolves to \emph{multiple objects} rather than
one; prior systems assume single-object resolution and either reject it
(Scala) or diverge (NixOS module system).
Self-referential records require no fixed-point combinator---the
composition tree \emph{is} the call stack, and qualified this resolution
is a first-order set-theoretic query, not a fixed-point construction.
These are not properties we engineered; they are phenomena we observed
in working programs.

This paper distills these observations into \textbf{Overlay-Calculus},
a minimal computational model for declarative programming.
It turns out that
\emph{function application has a straightforward translation into inheritance}:
a $\lambda$-abstraction corresponds to a record with an
$\mathrm{argument}$ slot and a $\mathrm{result}$ slot, and function
application corresponds to composing the function record with a record
that supplies the argument. Since the $\lambda$-calculus embeds into
Overlay-Calculus, Overlay-Calculus is Turing complete.
The translation reveals an \emph{asymmetry}:
while embedding the $\lambda$-calculus into Overlay-Calculus is trivial,
the reverse is non-trivial because Overlay-Calculus provides primitive
operations---self-referential records, open recursion, symmetric
composition---that have no direct counterparts in the $\lambda$-calculus.
Moreover, Overlay-Calculus naturally encodes random-access memory:
records are tries, and composition is trie union, yielding an
immutable analogue of the RAM machine
(Section~\ref{sec:trie}).
This asymmetry suggests that Overlay-Calculus is not merely a
syntactic variant of the $\lambda$-calculus but captures
different computational patterns.

Because every intermediate result in
Overlay-Calculus has a name, programs are inherently in A-normal
form~\cite{flanagan1993essence} with built-in dependency
injection---a property we call \emph{CPS-agnostic}
(Section~\ref{sec:cps-agnostic}).

The Expression Problem~\cite{wadler1998expression} solution of Wang and
Oliveira~\cite{wang2016trivially} ports from Scala (whose type system
rests on the DOT calculus~\cite{amin2016dot}) to Overlay-Calculus
in more concise form, despite Overlay-Calculus having only three
primitives whereas DOT is a substantially larger system.

Just as the $\lambda$-calculus uses three primitives (abstraction,
application, variable) to serve as the foundation of functional
programming, Overlay-Calculus uses three primitives (record, reference,
composition) to serve as the foundation of declarative programming.

All constructions in this paper have been implemented and tested in
the Overlay language,
\selfcite{available as open source~\cite{mixin2025}}{included as supplementary material},
with a test suite covering every example.
All tests are mechanically verified against expected output snapshots.

\paragraph{Contributions}
\begin{itemize}
  \item We present Overlay-Calculus, a minimal computational model for
    declarative programming that contains only overlay constructs (record,
    reference, composition) and no functions or scalar types.
  \item Composition operates at the \emph{tree level}:
    a record is a set of elements---property definitions and
    composition sources---so composing two overlays that share a label
    recursively merges their subtrees (union mount semantics), rather
    than overriding at the method level as in mixin and trait calculi.
    Since records are sets, composition is inherently commutative,
    idempotent, and associative.
    The linearization problem inherent in prior mixin and trait
    calculi simply does not arise.
  \item The semantics is purely \emph{observational}: there are no
    reduction rules, no evaluation order, and no notion of a result
    that a term reduces to.  The observer drives computation by
    querying paths in a lazily constructed tree.
  \item Self-referential records require no fixed-point combinator.
    The $\lambda$-calculus translation maps each application to a
    composition; the resulting composition tree \emph{is} the call stack.
    The $\this$ function of Section~\ref{sec:overlay-trees} resolves
    self-references by walking this tree---a first-order set-theoretic
    query, not a fixed-point construction.
  \item Self-reference resolves to \emph{multiple objects}, not one.
    Path-dependent types with composition naturally produce this
    situation; prior systems assume single-object resolution and
    either reject it (Scala; see Appendix~\ref{app:scala-multi-path})
    or diverge (NixOS module system).
    Since composition is idempotent, all objects contribute
    equally---no disambiguation is needed.
  \item The $\lambda$-calculus translates into Overlay-Calculus in three
    rules, so Overlay-Calculus is Turing complete.
    Composing this translation with the semantic functions
    induces a semantics on the $\lambda$-calculus that requires
    no function spaces, no substitution, and no reduction
    rules---only set membership in powerset lattices
    (Section~\ref{sec:translation}).
    Standard data types (booleans, natural numbers)
    can be Church-encoded without scalars (Appendix~\ref{app:church}).
  \item The Expression Problem~\cite{wadler1998expression} does not
    arise. Data definitions and operations are independent overlays;
    tree-level composition recursively merges their subtrees, making
    new operations available wherever the data type appears---including
    in return types of independently defined operations
    (Section~\ref{sec:discussion-expression-problem}).
    No design pattern is needed---this is simply what composition does.
  \item The distinction between CPS and direct style does not arise:
    programs are \emph{CPS-agnostic}.
    Every intermediate result has a name (A-normal form), and empty
    record slots serve as dependency injection points.
    Whether a slot is filled by an external orchestrator or composed
    locally is an assembly-time choice; the calculus defines no
    continuation primitive and draws no distinction between the two.
\end{itemize}

\paragraph{Informal example}\label{sec:expression-problem}
The Expression Problem~\cite{wadler1998expression}
asks how to extend a data type with both new cases and new operations,
without modifying existing code.
In a typed setting this additionally requires static type safety;
Overlay-Calculus is untyped, so we focus on the extensibility aspect.
Suppose a standard library provides a $\mathrm{binnat}$ module for
binary natural arithmetic (see Appendix).
We define an expression language with an evaluation operation:
\begin{align*}
  \{ \quad \mathrm{expression} &\mapsto \{
      \mathrm{Constant} \mapsto \{\mathrm{magnitude} \mapsto \{\}\},\;
      \mathrm{Addition} \mapsto \{\mathrm{left} \mapsto \{\},\;
    \mathrm{right} \mapsto \{\}\}\}, \\[4pt]
    \mathrm{evaluation} &\mapsto \{
      \mathrm{Constant} \mapsto \{
      \mathrm{expression}.\mathrm{Constant},\;
      \mathrm{outcome} \mapsto
      \qualifiedthis{\mathrm{Constant}}.\mathrm{magnitude}\}, \\
      &\qquad \mathrm{Addition} \mapsto \{
      \mathrm{expression}.\mathrm{Addition},\; \\
        &\qquad\qquad
        \mathrm{left\_outcome} \mapsto \qualifiedthis{\mathrm{Addition}}.\mathrm{left}.\mathrm{outcome},\\
        &\qquad\qquad
        \mathrm{right\_outcome} \mapsto \qualifiedthis{\mathrm{Addition}}.\mathrm{right}.\mathrm{outcome},\\
        &\qquad\qquad
        \mathrm{sum} \mapsto \{
        \mathrm{binnat}.\mathrm{Addition},\;
        \mathrm{augend} \mapsto
        \qualifiedthis{\mathrm{sum}}.\mathrm{left\_outcome},\;
        \mathrm{addend} \mapsto
        \qualifiedthis{\mathrm{sum}}.\mathrm{right\_outcome}\}, \\
        &\qquad\qquad
    \mathrm{outcome} \mapsto \mathrm{sum}.\mathrm{outcome}\}\},\\[4pt]
    \mathrm{binnat} &\mapsto \{
      \mathrm{Addition} \mapsto
      \{\mathrm{augend} \mapsto \{\},\;
        \mathrm{addend} \mapsto \{\},\;
    \mathrm{outcome} \mapsto \{\}\}\}
  \quad \}
\end{align*}
A new operation (e.g., display) is added by defining a new
module that inherits from the same $\mathrm{expression}$ schemas:
\begin{align*}
  \mathrm{display} \mapsto \{
    \mathrm{Constant} &\mapsto \{
    \mathrm{expression}.\mathrm{Constant},\;
    \mathrm{representation} \mapsto
    \qualifiedthis{\mathrm{Constant}}.\mathrm{magnitude}\},\\
    \mathrm{Addition} &\mapsto \{
    \mathrm{expression}.\mathrm{Addition},\;
    \mathrm{representation} \mapsto \{
        \mathrm{left} \mapsto
        \qualifiedthis{\mathrm{Addition}}.\mathrm{left}.\mathrm{representation},\;
  \mathrm{right} \mapsto
  \qualifiedthis{\mathrm{Addition}}.\mathrm{right}.\mathrm{representation}\}\}\}
\end{align*}
A new case (e.g., negation) is added with its operation handlers
and an empty API for the arithmetic primitive:
\begin{align*}
  \mathrm{negation} &\mapsto \{
    \mathrm{Negation} \mapsto
  \{\mathrm{operand} \mapsto \{\}\}\}, \\
  \mathrm{negation\_evaluation} &\mapsto \{
    \mathrm{Negation} \mapsto
    \{\mathrm{negation}.\mathrm{Negation},\;\\
      &\qquad
      \mathrm{operand\_outcome} \mapsto
      \qualifiedthis{\mathrm{Negation}}.\mathrm{operand}.\mathrm{outcome},\\
      &\qquad
      \mathrm{negated} \mapsto \{
      \mathrm{binnat}.\mathrm{Negation},\;
      \mathrm{operand} \mapsto
      \mathrm{operand\_outcome}\},\\
      &\qquad
  \mathrm{outcome} \mapsto
  \mathrm{negated}.\mathrm{outcome}\}\}, \\
  \mathrm{binnat} &\mapsto \{
    \mathrm{Negation} \mapsto
    \{\mathrm{operand} \mapsto \{\},\;
  \mathrm{outcome} \mapsto \{\}\}\}
\end{align*}
All modules compose freely; none requires modification of
existing definitions.
A complete executable version of this example---including both the
evaluation and display operations, a negation extension, and their free
composition---is \selfcite{available in the implementation~\cite{mixin2025}}{included in the supplementary material}, along with test
cases verifying evaluation and display for nested expressions mixing old
and new cases.

Note that $\mathrm{magnitude} \mapsto \{\}$ in $\mathrm{Constant}$
resembles a type annotation but is purely structural in Overlay-Calculus:
the evaluator works as long as the required properties appear somewhere in
the composition chain, regardless of any schema declarations.

\section{Syntax}
\label{sec:syntax}

Let $e$ denote an expression.
Let $\ell$ denote a label (property name).
Let $k$ denote a non-negative integer (path length).

\begin{align*}
  e \quad ::= \quad & \{c_1,\; \ldots,\; c_n\}
  && \text{(} n \ge 0 \text{)} \\
  \mid\quad & c
  && \text{(sugar for } \{c\} \text{)} \\[6pt]
  c \quad ::= \quad & \ell \mapsto e
  && \text{(property definition)} \\
  \mid\quad & [\qualifiedthis{\ell_{\mathrm{up}}}.]\;\ell_{\mathrm{down},1}.\ell_{\mathrm{down},2}\ldots\ell_{\mathrm{down},k}
  && \text{(reference, } k \ge 0 \text{ with qualifier, } k \ge 1 \text{ without)}
\end{align*}

An expression is a \emph{set} of elements enclosed in braces.
Each element is either a property definition $\ell \mapsto e$ or
a reference (composition source).
Because expressions are sets, element order is irrelevant and
duplicates have no effect---composition is inherently commutative,
idempotent, and associative.

The $\mapsto$ in $\ell \mapsto e$ defines a property, not a let-binding.
There is no variable binding in Overlay-Calculus.
The Overlay language also provides scalar types through a
foreign-function interface (FFI); Overlay-Calculus is what remains
after removing the FFI.
None of the examples in this paper uses the FFI---scalars simply
did not arise.

\paragraph{Reference}
A reference
$\qualifiedthis{\ell_{\mathrm{up}}}.\ell_{\mathrm{down},1}\ldots\ell_{\mathrm{down},k}$
is analogous to Java's
\texttt{Outer.this.field}. Each $\{\ldots\}$ record has a label in its
enclosing scope; $\ell_{\mathrm{up}}$ names the target enclosing scope.
The \emph{qualified this} $\qualifiedthis{\ell_{\mathrm{up}}}$ retrieves the \emph{dynamic self} of that scope---the
fully composed record after all compositions have been applied.
The suffix $\ell_{\mathrm{down},1}\ldots\ell_{\mathrm{down},k}$ then projects properties from the
dynamic self.

A new scope level is created at each $\{\ldots\}$ (record literal).
The scope contains all properties of that overlay, including those
inherited via composition sources.
For example, $\{a \mapsto \{\},\; b \mapsto \{\}\}$ is a single overlay whose scope
contains both $a$ and $b$; so is $\{r,\; a \mapsto \{\}\}$ where $r$
is a reference to a record containing $b$.
Composition sources do not create additional scope levels.

\begin{itemize}
  \item $\qualifiedthis{\mathrm{Foo}}$ retrieves the dynamic self of the nearest
    enclosing record named $\mathrm{Foo}$.
  \item $\qualifiedthis{\mathrm{Foo}}.\ell$ projects property $\ell$ from the
    dynamic self of $\mathrm{Foo}$.
  \item When $k = 0$, the reference $\qualifiedthis{\ell_{\mathrm{up}}}$ inherits the entire
    enclosing scope, which may produce an infinitely deep tree.
\end{itemize}

When the qualifier is unambiguous, it may be omitted:
the shorthand
$\ell_{\mathrm{down},1}.\ell_{\mathrm{down},2}\ldots\ell_{\mathrm{down},k}$ ($k \ge 1$)
resolves $\ell_{\mathrm{down},1}$ against the innermost enclosing
scope whose $\ownproperties$ contains it,
and desugars to the corresponding qualified this.
Since this uses $\ownproperties$, the shorthand can only access
properties defined in record literals, not those inherited through
composition; the qualifier is required for inherited properties
or to bypass variable shadowing.

\section{Overlay Trees}
\label{sec:overlay-trees}

Given an AST, what are the \emph{properties} visible at
each position in the tree? This section answers the question by
defining a collection of mutually recursive functions over paths.

Unlike the $\lambda$-calculus, which requires reduction rules
($\beta$-reduction) to specify how terms compute, Overlay-Calculus has
\emph{no reduction steps}. There is no rewriting of terms, no
evaluation order, and no notion of a ``result'' that a term reduces to.
Instead, the semantics is purely \emph{observational}: one queries
whether a label $\ell$ is a property at a path $p$ in the composed
tree. The mutually recursive functions defined below---$\properties$,
$\supers$, $\overlays$, $\bases$, $\resolve$, $\this$---constitute the
\emph{entire} semantics. This is the observational perspective
introduced in Section~\ref{sec:introduction}: like an
F-coalgebra~\cite{rutten2000universal}, an overlay tree's behavior is
determined by observation (property presence), not by reduction.

Most of these functions have direct analogues in object-oriented languages:
$\Path$ identifies a position in the tree,
$\init$ and $\last$ navigate paths,
$\ownproperties$ extracts the locally defined members from the AST,
$\references$ extracts the inheritance declarations from the AST,
$\properties$ computes all visible members at a path including both locally defined and inherited ones,
$\supers$ computes the transitive inheritance closure,
and $\bases$ collects the direct base classes.
One function has no object-oriented analogue:
$\overlays$ collects the identity-sharing paths that arise
when composition introduces multiple definitions
of the same label at the same scope level.
Two functions, the reference resolution function $\resolve$
and the qualified this resolution function $\this$,
have object-oriented analogues whose semantics differ significantly;
they are discussed in detail below.

All functions are pure and may be cached (memoised) without
changing semantics.

\paragraph{Path}
A $\Path$ is a sequence of labels
$(\ell_1, \ell_2, \ldots, \ell_n)$ that identifies a position in
the tree.%
\footnote{Since paths are referentially transparent,
  an implementation may \emph{intern} paths so that
  structural equality reduces to pointer equality.}
We write $p$ for a path.
The \emph{root path} is the empty sequence $()$.
Given a path $p$ and a label $\ell$,
$p \snoc \ell$ is the sequence $p$ extended with $\ell$.
For a non-root path, the parent path $\init(p)$ is $p$ with
its last element removed,
and the final label $\last(p)$ is the last element of $p$.
For convenience, we sometimes write $\ell$ for $\last(p)$
when the path is clear from context.
With paths in hand, we can state what the AST provides
at each path.

\paragraph{AST}
An expression $e$ (Section~\ref{sec:syntax}) is parsed into an AST.
The AST provides two primitive functions at each path $p$:
\begin{itemize}
  \item $\ownproperties(p)$: the set of labels
    that have subtrees at $p$.
  \item $\references(p)$: the set of reference pairs
    $(n,\; \ell_{\mathrm{down},*})$,
    where $n$ is the de~Bruijn index~\cite{debruijn1972lambda} (zero-based)
    and $\ell_{\mathrm{down},*}$ is the list of downward projections.
\end{itemize}

During parsing, both syntactic forms (with and without qualifier)
are resolved to de~Bruijn index pairs.
A qualified this reference
$\qualifiedthis{\ell_{\mathrm{up}}}.\ell_{\mathrm{down},1}\ldots\ell_{\mathrm{down},k}$
at path $p$ is resolved by finding the last occurrence of
$\ell_{\mathrm{up}}$ among the labels of $p$.
Let $p_{\mathrm{def}}$ be the prefix of $p$ up to and including
that occurrence.
The \emph{de~Bruijn index} $n$ is the number of labels in $p$
after that occurrence, i.e., $n = |p| - |p_{\mathrm{def}}|$.
The projections are
$\ell_{\mathrm{down},*} = (\ell_{\mathrm{down},1}, \ldots, \ell_{\mathrm{down},k})$.
A lexical reference $\ell_{\mathrm{down},1}.\ell_{\mathrm{down},2}\ldots\ell_{\mathrm{down},k}$ at path $p$
is resolved by finding the nearest prefix $p'$ of $p$
such that $\ell_{\mathrm{down},1} \in \ownproperties(p')$.
The de~Bruijn index is $n = |p| - |p'|$ and the projections are
$\ell_{\mathrm{down},*} = (\ell_{\mathrm{down},1}, \ldots, \ell_{\mathrm{down},k})$.
Both forms produce the same representation; the semantic functions
below operate only on de~Bruijn index pairs.

Parsing populates $\ownproperties$ and $\references$ from each
element of a record.
A property definition $\ell \mapsto e$
contributes $\ell$ to $\ownproperties(p)$.
A reference contributes $(n,\; \ell_{\mathrm{down},*})$ to $\references(p)$.
Since records are sets, the order of elements is irrelevant and
duplicate elements have no effect.
Both $\ownproperties$ and $\references$ are pure data; they are not functions
of runtime state.
Given these two primitives, we can now answer the question
posed at the beginning of this section.

\paragraph{Properties}
The properties of a path are its own properties together with
those inherited from all supers:
\begin{equation}\label{eq:properties}
  \properties(p) =
  \bigl\{\; \ell \;\big|\;
  (\_,\; p_{\mathrm{overlay}}) \in \supers(p),\;
  \ell \in \ownproperties(p_{\mathrm{overlay}})
  \;\bigr\}
\end{equation}
The remainder of this section defines $\supers$,
the transitive inheritance closure,
and its dependencies.

\paragraph{Supers}
Intuitively, $\supers(p)$ collects every path that $p$ inherits from:
the identity-sharing paths $\overlays$ of $p$ itself,
plus the $\overlays$ of each
direct base $\bases$ of $p$, and so on transitively.
Each result is paired with the composition-site context
$\init(p_{\mathrm{base}})$ through which it is reached.
This provenance is needed by qualified this resolution, i.e.\ the $\this$ function defined below,
to map a definition-site overlay back to
the composition-site paths that incorporate it:
\begin{equation}\label{eq:supers}
  \supers(p) =
  \bigl\{\; (\init(p_{\mathrm{base}}),\; p_{\mathrm{overlay}}) \;\big|\;
  p_{\mathrm{base}} \in \bases^*(p),\;
  p_{\mathrm{overlay}} \in \overlays(p_{\mathrm{base}})
  \;\bigr\}
\end{equation}
The $\supers$ formula depends on two functions:
the identity-sharing paths $\overlays$ and the one-hop reference targets $\bases$.
We define $\overlays$ first.

\paragraph{Overlays}
Intuitively, composition can introduce multiple
definitions of the same label at the same scope level;
$\overlays(p)$ collects all such paths that share the
\emph{same identity} as $p$.
Concretely, the overlays of $p$ include $p$ itself
and $p_{\mathrm{branch}} \snoc \last(p)$ for every
branch $p_{\mathrm{branch}}$ of $\init(p)$ that also defines $\last(p)$:
\begin{equation}\label{eq:overlays}
  \overlays(p) =
  \begin{cases}
    \{p\} & \text{if } p = ()  \\[6pt]
    \{p\}
    \;\cup\;
    \left\{\; p_{\mathrm{branch}} \snoc \last(p) \;\left|\;
    \begin{aligned}
      &(\_,\; p_{\mathrm{branch}}) \in \supers(\init(p)), \\
      &\text{s.t.}\; \last(p) \in \ownproperties(p_{\mathrm{branch}})
    \end{aligned}
    \right.\right\}
    & \text{if } p \neq ()
  \end{cases}
\end{equation}
It remains to define $\bases$, the other dependency of $\supers$.

\paragraph{Bases}
Intuitively, $\bases(p)$ are the paths that $p$ directly
inherits from via references---analogous to the direct base
classes in object-oriented languages.
Concretely, $\bases$ resolves every reference in
$p$'s $\overlays$ one step:
\begin{equation}\label{eq:bases}
  \bases(p) =
  \left\{\; p_{\mathrm{target}} \;\left|\;
  \begin{aligned}
    &p_{\mathrm{overlay}} \in \overlays(p), \\
    &(n,\; \ell_{\mathrm{down},*}) \in \references(p_{\mathrm{overlay}}), \\
    &p_{\mathrm{target}} \in \resolve(\init(p),\; p_{\mathrm{overlay}},\; n,\; \ell_{\mathrm{down},*})
  \end{aligned}
  \right.\right\}
\end{equation}
The $\bases$ formula calls the reference resolution function $\resolve$, which we define next.

\paragraph{Reference resolution}
Intuitively, $\resolve$ turns a syntactic reference into the
set of paths it points to in the fully composed tree.
It takes a composition-site path $p_{\mathrm{site}}$,
a definition-site path $p_{\mathrm{def}}$,
a de~Bruijn index $n$,
and downward projections $\ell_{\mathrm{down},*}$.
Resolution proceeds in two phases: first, the qualified this resolution function $\this$ performs $n$ upward steps
starting from the enclosing scope $\init(p_{\mathrm{def}})$,
mapping the definition-site path to composition-site paths;
then the downward projections $\ell_{\mathrm{down},*}$ are appended:
\begin{equation}\label{eq:resolve}
  \resolve(p_{\mathrm{site}},\; p_{\mathrm{def}},\; n,\; \ell_{\mathrm{down},*})
  =
  \bigl\{\;
  p_{\mathrm{current}} \snoc \ell_{\mathrm{down},1} \snoc \cdots \snoc \ell_{\mathrm{down},k}
  \;\big|\;
  p_{\mathrm{current}} \in
  \this(\{p_{\mathrm{site}}\},\; \init(p_{\mathrm{def}}),\; n)
  \;\bigr\}
\end{equation}
When multiple routes exist (due to multi-path inheritance from composition),
they may yield different target paths; all are collected.
We now define $\this$.

\paragraph{Qualified this resolution}
Intuitively, $\this$ answers the question:
``in the fully composed tree, where does
the definition-site scope $p_{\mathrm{def}}$ actually live?''
The design of $\this$ reconciles two historically opposing
approaches to scope resolution.
Early Lisp implementations used dynamic scope~\cite{mccarthy1978history},
where variable references are resolved against the run-time call stack;
this is flexible but unpredictable.
Scheme~\cite{sussman1975scheme} corrected this with lexical scope,
where a de~Bruijn index resolves in a single step by indexing
into the statically determined environment;
this is predictable but rigid.
Scala~\cite{odersky2004overview} and the NixOS module
system~\cite{nixosmodules} follow the lexical approach:
each \texttt{this} reference is bound to a single
statically known path.
When composition introduces multiple inheritance routes
to the same scope, Scala rejects the ambiguity at compile time
(Appendix~\ref{app:scala-multi-path})
and the NixOS module system enters an infinite loop---neither
can express that all routes are equally valid.

Overlay-Calculus combines the strengths of both approaches.
The reference itself is lexically determined at the definition site
as a de~Bruijn index, so what $\this$ looks up is predictable.
But because composition interleaves scopes from
different overlays, the result depends on the composed tree
structure: $\this$ walks upward one scope level at a time,
consulting $\supers$ at each level, and naturally tracks a
\emph{set} of composition-site paths rather than a single one.
All routes contribute equally to the composed result, and since
composition is idempotent, duplicated contributions are harmless.
The only observable is property presence, making
multi-path resolution well-defined without disambiguation.

Concretely, each step finds, among the supers of every path in the
frontier $S$, those whose overlay component matches
$p_{\mathrm{def}}$, and collects the corresponding
composition-site paths as the new frontier.
After $n$ steps the frontier contains the answer:
\begin{equation}\label{eq:this}
  \this(S,\; p_{\mathrm{def}},\; n) =
  \begin{cases}
    S & \text{if } n = 0 \\[6pt]
    \this\!\left(
    \left\{\; p_{\mathrm{site}} \;\left|\;
    \begin{aligned}
      &p_{\mathrm{current}} \in S, \\
      &(p_{\mathrm{site}},\; p_{\mathrm{overlay}})
      \in \supers(p_{\mathrm{current}}), \\
      &\text{s.t.}\; p_{\mathrm{overlay}} = p_{\mathrm{def}}
    \end{aligned}
    \right.\right\},\;
    \init(p_{\mathrm{def}}),\;
    n - 1
    \right)
    & \text{if } n > 0
  \end{cases}
\end{equation}
At each step $\init$ shortens $p_{\mathrm{def}}$ by one label
and $n$ decreases by one.
Since $n$ is a non-negative integer, the recursion terminates.

\paragraph{Alternative approaches considered}
Our first three implementations of the Overlay language used
standard techniques for self-reference resolution: closure-based
fixed points following Cook~\cite{cook1989denotational}, and
stack-based environment lookup using de~Bruijn
indices~\cite{debruijn1972lambda}.
All three produced subtle bugs when composition introduced
multiple inheritance routes to the same enclosing scope.

In retrospect, the difficulty was inevitable.
A closure captures a single environment, so a fixed-point
combinator solves for a single self-reference; when multiple
routes exist, it attempts to unify them into one value.
A stack-based environment is a linear chain---each scope level
has one parent---so looking up a de~Bruijn index returns a single
value.
Both data structures embed a single-valued assumption that is
incompatible with the multi-path situation that arises when
independent overlays inherit from the same enclosing scope
(Appendix~\ref{app:scala-multi-path}).
Equation~(\ref{eq:this}) emerged from recognizing this: it
operates on paths as first-order data and tracks a \emph{frontier
set} $S$ rather than a single current scope.

This completes the chain of definitions needed to compute $\properties(p)$.

\paragraph{Observational semantics without reduction}
The definitions above constitute the complete semantics of
Overlay-Calculus. There are no reduction rules, no evaluation contexts,
and no small-step or big-step judgments. This is a deliberate design
choice, not an omission. In the $\lambda$-calculus, a term such as
$(\lambda x.\, x)\; y$ must be \emph{reduced} to $y$ before its
meaning is apparent; the operational semantics specifies how and in what
order reductions occur. In Overlay-Calculus, a composed tree such as
$\{a \mapsto \{\},\; b \mapsto \{\}\}$ does not reduce to
anything---it \emph{is} the value. The functions $\properties$,
$\supers$, etc.\ determine what is observable at each path, and that is
all. Computation arises not from rewriting terms but from querying an
inductively deeper path in a lazily constructed tree: the observer
drives the computation by choosing which path to inspect, and the
mutually recursive definitions unfold on demand.
Formally, the mutually recursive equations
(\ref{eq:properties})--(\ref{eq:this}) define set membership
\emph{inductively}: $\ell \in \properties(p)$ holds if and only if
it can be established by a finite chain of applications of these
equations.  The corresponding operator on the product lattice of
path sets is monotone, and its least fixed point
exists by the Knaster--Tarski theorem~\cite{tarski1955lattice}.
The detailed well-definedness argument---identifying the lattice,
verifying positivity of each equation, and handling the transitive
closure $\bases^*$---is given in Appendix~\ref{app:well-definedness}.
When no finite derivation exists for a given query, the
membership is not in this least fixed point and the semantics is
undefined at that point---analogous to divergence in the
$\lambda$-calculus, and the expected consequence of Turing
completeness.
This observation model
is inspired by F-coalgebras~\cite{rutten2000universal}, where
identity is determined by observable behavior rather than by internal
structure.

\section{Relationship to Other Computational Models}
\label{sec:relationship}

\subsection{Translation from $\lambda$-Calculus}
\label{sec:translation}

The following translation maps the $\lambda$-calculus to Overlay-Calculus.
Let $\mathcal{T}$ denote the translation function,
mapping a $\lambda$-term to an Overlay-Calculus expression.
Each $\lambda$-abstraction is assigned a unique label
$\mathrm{fn}_i$ in its enclosing scope.

\medskip
\begin{center}
  \begin{tabular}{l@{\qquad$\longrightarrow$\qquad}l}
    $x$ (variable) &
    $\qualifiedthis{\mathrm{fn}_x}.\mathrm{argument}$ \\
    $\lambda x.\, e$ (abstraction) &
    $\{\mathrm{argument} \mapsto \{\},\;
    \mathrm{result} \mapsto \mathcal{T}(e)\}$ \\
    $e_1\; e_2$ (application) &
    $\{\mathcal{T}(e_1),\;
    \mathrm{argument} \mapsto \mathcal{T}(e_2)\}$
  \end{tabular}
\end{center}
\medskip

A variable reference $x$ becomes
$\qualifiedthis{\mathrm{fn}_x}.\mathrm{argument}$, where $\mathrm{fn}_x$
is the label of the $\lambda$-abstraction that binds $x$.
The qualified this $\qualifiedthis{\mathrm{fn}_x}$ resolves to the dynamic
self of that abstraction's record, giving access to the
$\mathrm{argument}$ slot after all compositions.

The result of an application is accessed via $.\mathrm{result}$.
Nested applications require ANF-style naming of intermediate results.

The three rules above are a complete translation from the
$\lambda$-calculus to Overlay-Calculus: every $\lambda$-term has an
image, and the construction is compositional.
Since the $\lambda$-calculus is Turing complete, so is
Overlay-Calculus; Section~\ref{sec:trie} further shows that
Overlay-Calculus primitives directly encode a random-access machine.

\paragraph{An elementary semantics of the $\lambda$-calculus}
Composing the translation $\mathcal{T}$ with the semantic
functions of Section~\ref{sec:overlay-trees} induces a semantics
on the $\lambda$-calculus itself.
Given a $\lambda$-term $M$, one translates it to
$\mathcal{T}(M)$ and then determines observational behavior by
querying $\ell \in \properties(p)$ via
equations~(\ref{eq:properties})--(\ref{eq:this}).
The meaning of $M$ is fully determined by these path queries.

This induced semantics is more elementary than traditional
approaches in the mathematical machinery it requires:
\begin{itemize}
  \item \emph{No function spaces.}
    Scott's denotational semantics~\cite{scott1976data} constructs a
    reflexive domain $D$ satisfying $D \cong [D \to D]$ via an
    inverse limit in a category of continuous lattices.
    Here, the semantic domain is a product of powerset
    lattices---no function spaces, no continuity conditions,
    no inverse limits.
    The only fixed-point construction is Knaster--Tarski on
    powerset lattices
    (Appendix~\ref{app:well-definedness}), which requires
    only set-theoretic monotonicity---strictly weaker than
    Scott continuity.
  \item \emph{No substitution.}
    Operational semantics defines $\beta$-reduction via
    capture-avoiding substitution, a mechanism whose subtleties
    motivated de~Bruijn indices~\cite{debruijn1972lambda} and
    explicit substitution calculi.
    Here, variable references are resolved by the $\this$
    function walking the composition tree---no substitution
    occurs at any point.
  \item \emph{No reduction rules.}
    There are no $\beta$-reduction steps, no evaluation
    contexts, and no choice between call-by-name and
    call-by-value~\cite{plotkin1975callbyname}.
    The semantics is observational: one queries path
    membership, and the mutually recursive equations unfold
    on demand.
\end{itemize}
That a semantics of the $\lambda$-calculus can be given without
function spaces is perhaps unexpected: function application is
encoded as record composition, and the resulting record is
observed through path queries rather than applied as a function.
Proving that this induced semantics agrees with standard
denotational or operational semantics---i.e., that
observational equivalence is preserved by $\mathcal{T}$---is
left to future work.

The reverse direction is non-trivial, as we discuss next.

\subsection{Expressive Asymmetry}
\label{sec:asymmetry}

The translation above consists of three rules; the full computational
power of the $\lambda$-calculus embeds into Overlay-Calculus with no
additional machinery.

The reverse direction---encoding Overlay-Calculus in pure
$\lambda$-calculus---is non-trivial.
Defining the meaning of Overlay-Calculus requires machinery for
lazy allocation, recursive data structures, and set-valued
resolution that have no direct counterparts in the $\lambda$-calculus.
This sophistication is not accidental---it reflects three features:

\begin{enumerate}
  \item \textbf{Self-referential records with lazy evaluation.}
    An overlay's properties can reference other properties and enclosing scopes
    through qualified this without explicit binding.
    In the $\lambda$-calculus, encoding such self-referential
    structures requires explicit allocation of mutable or lazy
    references (e.g., Haskell-style thunks or ML-style \texttt{ref}
    cells), obscuring the declarative intent.

  \item \textbf{Open recursion with symmetric composition.}
    Composition merges definitions from independent sources,
    all sharing the same composed overlay tree. Encoding this in
    the $\lambda$-calculus requires maintaining an extensible dictionary
    of methods that can be merged from multiple directions. Cook's
    denotational semantics of inheritance~\cite{cook1989denotational}
    devoted an entire dissertation to formalizing this pattern in a
    functional setting.

  \item \textbf{Commutative, idempotent merge.}
    Composition in Overlay-Calculus is symmetric:
    a record's elements form a set, so reordering them produces
    the same observable result. In the $\lambda$-calculus, function composition
    $(f \circ g)$ is neither commutative nor idempotent, and simulating
    these properties requires additional machinery.
\end{enumerate}

\noindent
Overlay-Calculus is not the $\lambda$-calculus in disguise:
it provides primitive operations for computational patterns that are
\emph{derivable but complex} in the $\lambda$-calculus.

The reverse asymmetry also exists: nested expressions such as
$f\;(g\;x)$ are primitive in the $\lambda$-calculus but require
manual A-normal form conversion in Overlay-Calculus---the
intermediate result $g\;x$ must be given an explicit name.
However, ANF conversion is a trivial, mechanical
transformation~\cite{flanagan1993essence}; a surface language built
on Overlay-Calculus can support nested expressions as syntactic
sugar without extending the calculus itself.

\subsection{CPS-Agnostic Programs}
\label{sec:cps-agnostic}

In the $\lambda$-calculus, a program is either in continuation-passing
style (CPS) or direct style. Converting between these representations
requires explicit transformation---the CPS
conversion~\cite{plotkin1975callbyname,sabry1993reasoning}.
In Overlay-Calculus, the distinction does not exist: the same program text
is CPS or direct-style depending on how dependencies are assembled.

Consider a generic computation step:
\begin{align*}
  \mathrm{Step} \mapsto \{
    \mathrm{input} \mapsto \{\},\;
    \mathrm{process} \mapsto \{\},\;
    \mathrm{result} \mapsto \{\}
  \}
\end{align*}

The empty $\mathrm{process}$ slot is an \emph{interpretation point}. If
filled externally by an orchestrator, it acts as a continuation parameter
(CPS interpretation). If composed locally with an implementation, it acts
as a direct dependency (direct-style interpretation). The
$\mathrm{Step}$ code remains unchanged.

\paragraph{CPS interpretation via external orchestration}
When $\mathrm{process}$ is injected from outside, the computation passes
its intermediate result to an external handler:
\begin{align*}
  &\{\qualifiedthis{\mathrm{Step}},\; \\
    &\quad \mathrm{input} \mapsto \{\mathrm{data} \mapsto \{\}\},\; \\
    &\quad \mathrm{process} \mapsto \{ \\
      &\qquad \mathrm{result} \mapsto \{\mathrm{handled} \mapsto \{\}\} \\
    &\quad \} \\
  &\}
\end{align*}
The $\mathrm{process}$ slot acts as a continuation: it receives the
result and determines what happens next. This is CPS-style programming.

\paragraph{Direct-style interpretation via local composition}
Alternatively, $\mathrm{process}$ can be filled by local composition:
\begin{align*}
  &\{\qualifiedthis{\mathrm{Step}},\; \\
    &\quad \mathrm{input} \mapsto \{\mathrm{data} \mapsto \{\}\},\; \\
    &\quad \mathrm{process.result} \mapsto \{\mathrm{computed} \mapsto \{\}\} \\
  &\}
\end{align*}
Here $\mathrm{process}$ is implemented directly within the composition.
This is direct-style programming. The $\mathrm{Step}$ code is identical
in both cases---only the assembly strategy differs.

\paragraph{Representation independence}
This property is a form of representation
independence~\cite{reynolds1983types} applied to control flow: client
code using $\mathrm{Step}$ need not know whether $\mathrm{process}$ will
be filled continuation-style or directly. Library authors write code
once; users choose the control flow style at assembly time.

The $\lambda$-calculus lacks this flexibility. A function written in
direct style must be explicitly transformed (CPS conversion) before it
can be used continuation-style. Overlay-Calculus programs are inherently in
A-normal form~\cite{flanagan1993essence}, where every intermediate result
has a name.

However, Overlay-Calculus ANF differs critically from ANF in functional
programming. In functional language compilers, ANF conversion requires
specifying a target monad---either a concrete monad or an abstract
one~\cite{moggi1991notions}. Compiler-internal ANF transformations (the
ANF form used in intermediate representations) typically target the
identity monad, which cannot express CPS transformations. This is
analogous to how imperative compilers use SSA (Static Single Assignment)
form, which similarly lacks control flow flexibility. Overlay-Calculus ANF,
by contrast, has built-in dependency injection: empty API slots can be
filled by external orchestrators. This capability enables the same ANF
program to serve both CPS and direct-style interpretations without monad
specification or transformation.

\paragraph{Multiple symmetric continuations}
When interpreted continuation-style, Overlay-Calculus naturally supports
multiple exit points:
\begin{align*}
  \mathrm{Choice} \mapsto \{
    \mathrm{on\_success} &\mapsto \{\},\; \\
    \mathrm{on\_failure} &\mapsto \{\},\; \\
    \mathrm{on\_timeout} &\mapsto \{\},\; \\
    \mathrm{result} &\mapsto \{\}
  \}
\end{align*}

All continuation slots are symmetric elements of the same record. Traditional CPS in
the $\lambda$-calculus distinguishes a single continuation parameter;
additional continuations must be encoded (e.g., as pairs or disjoint
sums). Overlay-Calculus treats all continuation slots uniformly, eliminating
the need for specialized encodings.

\paragraph{Abstract and concrete are syntactically identical}
From a category-theoretic perspective, abstract algebra and concrete
implementation have the same syntactic structure in Overlay-Calculus:
\begin{align*}
  \text{Abstract:} \quad & \mathrm{API} \mapsto \{\} \\
  \text{Concrete:} \quad & \mathrm{API} \mapsto \{\text{implementation}\}
\end{align*}

This is the abstract/concrete correspondence: the same functor applies to
both. In traditional languages, abstract interfaces (e.g., Java
interfaces, Haskell type classes) have different syntax from concrete
implementations. In Overlay-Calculus, they are syntactically
identical---only the interpretation differs. An empty API is
simultaneously an abstract requirement (when viewed as a dependency) and
a concrete extension point (when viewed as an injection site).

The Selector and Rebuilder combinators (Appendix~\ref{app:trie})
demonstrate this flexibility: their callback slots
($\mathrm{on\_zero}$, $\mathrm{on\_odd}$, $\mathrm{on\_even}$) can be
filled externally (CPS interpretation) or composed locally (direct
interpretation).

\paragraph{Practical implications}
A library component with empty API slots can be used in multiple
contexts without modification:
\begin{itemize}
  \item In synchronous code, fill slots with direct implementations
  \item In asynchronous code, fill slots with continuation handlers
  \item In effect systems, compose with algebraic effect handlers~\cite{plotkin2003algebraic}
  \item In test code, fill slots with mock implementations
\end{itemize}

No dual APIs are needed. The same component serves all use cases. This
eliminates a common source of code duplication in traditional languages,
where async and sync versions of the same functionality must be
maintained separately.

\selfcite{The implementation~\cite{mixin2025} includes}{The supplementary material includes} executable examples of all three
patterns described above: escape continuations analogous to
\texttt{call/cc}, success/failure continuations analogous to exception
handling, and protected computations with multiple symmetric exit points.
Each example includes test cases verifying that the correct continuation
path is taken.

CPS-agnosticism is not a designed feature of Overlay-Calculus; it is
an emergent property of records and composition. The calculus
defines no notion of continuation---the three syntax constructs and
six semantic functions of Section~\ref{sec:overlay-trees} are the
entire language.

\subsection{Records as Tries: The RAM Machine Connection}
\label{sec:trie}

A record $\{\ell_1 \mapsto e_1,\; \ldots,\; \ell_n \mapsto e_n\}$ is
a trie node: each label selects a subtree. Nested records form a
trie whose depth corresponds to key length. Composition is
natively trie union: merging two records combines their subtrees
recursively. This observation yields an immutable analogue of
random-access memory.

The fundamental operations on random-access memory correspond directly
to Overlay-Calculus primitives:
\begin{itemize}
  \item \textbf{Write}: composing a singleton trie (adding it as
    a composition source).
  \item \textbf{Read (static)}: reference resolution
    ($[\qualifiedthis{\ell_{\mathrm{up}}}.]\;\ell_{\mathrm{down},1}.\ell_{\mathrm{down},2}\ldots\ell_{\mathrm{down},k}$).
  \item \textbf{Read (dynamic)}: folding a key into a Selector
    combinator that navigates the trie at runtime.
  \item \textbf{Delete}: folding a key into a Rebuilder combinator
    that reconstructs the trie, omitting the targeted entry.
  \item \textbf{Update}: composing deletion with insertion.
\end{itemize}

\noindent
In the $\lambda$-calculus, implementing a persistent trie with
efficient union requires explicit data structure encodings
(e.g., hash array mapped tries or finger trees). In Overlay-Calculus,
records \emph{are} tries and composition \emph{is} trie union---no
additional data structure is needed.
The full constructions (Selector, Rebuilder, Lookup, Delete, Update)
are given in Appendix~\ref{app:trie}.
\selfcite{The implementation~\cite{mixin2025} includes}{The supplementary material includes} executable implementations of all
trie operations---static and dynamic lookup, deletion, update, and trie
union---with test cases covering keys of varying bit structure.
Together, these operations constitute an immutable random-access machine
with random-access time complexity.

\subsection{Contrast with SKI Combinator Calculus}

A natural question arises: is Overlay-Calculus merely another function-free
reformulation of the $\lambda$-calculus, analogous to the SKI combinator
calculus~\cite{schonfinkel1924,curry1958combinatory}?

Like Overlay-Calculus, the SKI combinator calculus is function-free at the
object level (no $\lambda$-abstractions), Turing complete, and minimal
(three combinators). However, SKI is \emph{isomorphic} to the
$\lambda$-calculus in terms of problem difficulty: the bracket
abstraction algorithm translates between the two systems while
preserving computational structure. Problems that are hard in the
$\lambda$-calculus---such as the Expression
Problem~(Section~\ref{sec:expression-problem})---remain equally hard
in SKI.

In Overlay-Calculus, the Expression Problem---which requires object
algebras~\cite{oliveira2012extensibility}, finally tagless
interpreters~\cite{carette2009finally}, or multi-parameter type
classes in $\lambda$-calculus-based systems---is just composition.
Random-access memory via immutable tries---which requires
explicit data structure engineering in the $\lambda$-calculus---is
just the native record structure
(Section~\ref{sec:trie}). These are not problems that Overlay-Calculus
\emph{solves}; they are problems that do not arise.

\section{Discussion}

\subsection{Is Overlay-Calculus Just Functions in Disguise?}

A skeptical reader might ask whether Overlay-Calculus is simply
the $\lambda$-calculus with different syntax.

The semantic domain of Overlay-Calculus (Section~\ref{sec:overlay-trees}) is entirely
first-order: paths are label sequences, overlays are the record trees
produced by evaluation, AST nodes are pure data,
and the resolution functions ($\overlays$, $\supers$, $\resolve$, etc.)
are ordinary set-valued functions over these structures.
No function types appear in the object language or its semantics.
The crucial question is not what notation is used, but what
computational patterns are \emph{primitive} in the language itself.

In Overlay-Calculus, the primitive operations are record construction,
qualified-this reference, and composition. Function application is
\emph{derived} from these primitives (Section~\ref{sec:translation}), not primitive itself.
The asymmetry of Section~\ref{sec:asymmetry} makes this concrete:
embedding the $\lambda$-calculus into Overlay-Calculus requires three
rules; the reverse requires sophisticated encoding.
The test of whether two computational models are ``the same'' is
whether they make the same problems easy and the same problems hard.
They do not:

\begin{center}
  \begin{tabular}{lll}
    \textbf{System} & \textbf{Expression Problem} & \textbf{Random-access memory} \\
    \hline
    $\lambda$-calculus
    & Object algebras~\cite{oliveira2012extensibility},
    & Explicit trie encoding \\
    & finally tagless~\cite{carette2009finally} & \\
    SKI combinators
    & Same difficulty as $\lambda$
    & Same difficulty as $\lambda$ \\
    Overlay-Calculus
    & Direct composition
    & Records \emph{are} tries \\
  \end{tabular}
\end{center}

\noindent
Overlay-Calculus requires no additional machinery for either
problem class; the $\lambda$-calculus requires elaborate
encodings for both.

\paragraph{Why tree-level composition dissolves the Expression
Problem.}
\label{sec:discussion-expression-problem}
Each operation is an independent overlay that extends a factory's
subtree. Composition recursively merges subtrees that share a label,
so every entity in the factory acquires all operations from all
composed overlays.
Crucially, this applies to return types: if operation~$A$ returns
values from factory~$F$, and an independently defined overlay~$B$
adds a property to~$F$, then composing $A$ and~$B$ causes the
values returned by~$A$ to carry that property automatically---without
modifying either~$A$ or~$B$.
In object algebras~\cite{oliveira2012extensibility} and finally
tagless interpreters~\cite{carette2009finally}, independently defined
operations do not automatically enrich each other's return types;
additional boilerplate or type-class machinery is required.

Multi-path qualified this (equation~\ref{eq:this}) is essential to
this dissolution---not merely to \emph{solving} the Expression
Problem (for which many solutions
exist~\cite{oliveira2012extensibility,carette2009finally}), but to
making it \emph{not arise} in the first place.
In the informal example of Section~\ref{sec:expression-problem},
$\mathrm{evaluation}.\mathrm{Constant}$ and
$\mathrm{display}.\mathrm{Constant}$ both inherit
$\mathrm{expression}.\mathrm{Constant}$.
When the two operations are composed, the resulting
$\mathrm{Constant}$ inherits the $\mathrm{expression}$ schema
through two independent routes.
The reference
$\qualifiedthis{\mathrm{Constant}}.\mathrm{magnitude}$
inside each operation resolves through both routes, and since
composition is idempotent, all routes contribute the same
properties.
In Scala, the same pattern---two independently defined inner
classes extending the same outer class's trait---triggers a
``conflicting base types'' rejection
(Appendix~\ref{app:scala-multi-path}), because DOT's self variable
is single-valued and cannot resolve through multiple inheritance
routes simultaneously.
The Expression Problem can still be \emph{solved} in Scala using
object algebras or similar patterns, but it cannot be made to
\emph{not arise}: free composition of independently defined
operations inherently produces multi-path inheritance to shared
schemas, which DOT's single-valued self variable cannot
accommodate.

\subsection{Properties of Composition}

Because records are sets, composition is inherently commutative
and idempotent, making Overlay-Calculus transparent to
linearization order.
Deduplication of inherited overlays is purely an optimization.

\subsection{Relationship to Practical Systems}

Several classes of declarative systems that have emerged independently
in practice turn out to be instances of Overlay-Calculus.

\paragraph{Configuration and object-oriented languages}
The NixOS module system~\cite{dolstra2008nixos,nixosmodules}---whose
recursive attribute merging motivated this work---can be understood as an
implementation of Overlay-Calculus with additional features (type checking,
error reporting, FFI to the Nix language).
Detailed comparisons with CUE, Jsonnet, Dhall, with mixin and
trait calculi, and with the NixOS module system's lazy evaluation
limitations under multiple inheritance routes are given in
Section~\ref{sec:related-work}.

\paragraph{Effect systems}
Algebraic effects with handlers~\cite{plotkin2003algebraic,pretnar2015introduction}
and monad transformers structure computational effects through composition.
The CPS-agnostic property (Section~\ref{sec:cps-agnostic}) shows how Overlay-Calculus naturally
supports effect handler composition: empty API slots can be filled with
effect handlers (CPS interpretation) or direct implementations (direct-style
interpretation). The same pattern appears in algebraic effect systems, without
explicit monad machinery.

\paragraph{Modular software architectures}
Plugin systems, component frameworks, and dependency injection frameworks
enable software extensibility through declarative composition. The
symmetric, associative nature of composition (Section~\ref{sec:overlay-trees}) explains why such
systems work: components can be composed in any order without changing
behavior. These systems implement Overlay-Calculus patterns ad hoc.

\paragraph{Union file systems}
Union file systems (UnionFS, OverlayFS, AUFS) layer multiple directory
hierarchies to present a unified view. The composition semantics directly
mirror Overlay-Calculus: later layers override earlier layers (asymmetric
composition), files from all layers remain accessible (non-destructive
merging), and composition order affects conflict resolution (non-commutative
when scalar files conflict). We implemented Overlay-Calculus
in a union file
system\selfcite{~\cite{ratarmount2025}}{~(included as supplementary material)};
late-binding semantics and dynamic dispatch for file lookups across
layers required no additional mechanism beyond the three primitives.
In package managers, build systems, and OS distributions,
external toolchains transform configuration into file trees;
here, the file system serves as configuration to itself,
and the transformation is composition.

\section{Related Work}
\label{sec:related-work}

\paragraph{Denotational semantics of inheritance}
Cook~\cite{cook1989denotational} gave the first denotational
semantics of inheritance, modeling objects as recursive records and
inheritance as composition of \emph{generators} (functions from self
to complete object) and \emph{wrappers} (functions that modify
generators), solved by a fixed-point construction.
Cook's key insight---that inheritance is a general mechanism
applicable to any form of recursive definition, not only
object-oriented methods---is one of the starting points of the
present work.
The model has four primitives (records, functions, generators,
wrappers) and requires a fixed-point combinator; composition is
asymmetric (a wrapper modifies a generator, not vice versa).
Whether the same insight can be captured with fewer primitives and
symmetric composition was a natural question.

\paragraph{Mixin-based inheritance}
Bracha and Cook~\cite{bracha1990mixin} formalized mixins as
abstract subclasses---functions from a superclass parameter to a
subclass---unifying the inheritance mechanisms of Smalltalk, Beta,
and CLOS under a single model.
Because mixin application is function composition, it is
\emph{neither commutative nor idempotent}: applying the same
mixin twice may produce different results, and applying two
mixins in different orders may yield different linearizations.
The C3 linearization algorithm~\cite{c3linearization} was later
developed to impose a deterministic order;
whether linearization is inherent to inheritance or an artifact of
non-commutativity was worth examining.
Mixin composition operates at the \emph{method level}: applying a
mixin replaces or extends individual methods in a flat namespace.
There is no recursive merging of nested structure---composing two
mixins that define the same method name results in an override, not
a union mount.
Finally, mixins presuppose the $\lambda$-calculus as their
computational foundation: method bodies are functions, and mixin
application is function composition.
Mixins organize and compose functions but cannot replace
them---without the underlying $\lambda$-calculus, there is nothing
to compose.  The mixin mechanism itself is not Turing complete.

\paragraph{Traits}
Sch\"arli et al.~\cite{scharli2003traits} introduced traits as
composable units of behavior. Trait composition is symmetric and
commutative: the sum of two traits is order-independent, which is
a significant improvement over mixins.
However, when two traits provide methods with the
same name, a \emph{conflict} arises and must be explicitly resolved
by the programmer through exclusion or aliasing.
Ducasse et al.~\cite{ducasse2006traits} extended the model with a
\emph{flattening property}: the semantics of a class is independent
of whether its methods originate from traits or are defined directly.
Like mixins, trait composition is \emph{flat}: it operates on
individual method names, not on nested structures, so same-name
definitions are conflicts rather than opportunities for deeper
merging.
And like mixins, traits presuppose the $\lambda$-calculus: trait
methods are functions, and the computational power resides in those
functions, not in the trait mechanism itself.

\paragraph{Family polymorphism and virtual classes}
Ernst~\cite{ernst2001family} introduced family polymorphism, where
families of mutually dependent classes can be refined together in
subclasses. Ernst, Ostermann, and Cook~\cite{ernst2006virtual}
formalized this in the virtual class calculus, where classes are
class-valued attributes of objects, accessed via path expressions of
the form \texttt{this.out.C}.
The path \texttt{this.out} navigates to an enclosing scope, analogous
to qualified this ($\qualifiedthis{\ell_{\mathrm{up}}}$) in this paper.
A notable restriction is that each such path resolves to a
\emph{single} class in a \emph{single} enclosing object.
When multiple inheritance routes lead to the same scope---a common
situation under composition---single-valued resolution must choose
one route and discard the others, losing information.
Whether qualified this can resolve to a \emph{set} of paths,
letting all routes contribute equally, had not been
explored.

\paragraph{Object calculi}
Abadi and Cardelli~\cite{abadi1996theory} developed a comprehensive
theory of objects, treating objects---rather than classes---as the
primitive notion. Their calculi include method update and
self-referential objects, but methods are fundamentally functions
(taking self as a parameter), and object extension is asymmetric
(method override replaces the previous definition).
Boudol~\cite{boudol2004recursive} studied the recursive record
semantics of objects in a call-by-value setting, showing that
self-referential records require an unsafe fixed-point operator.
Whether self-reference can be handled without a fixed-point operator
in the object language---for instance, through coalgebraic
observation rather than reduction---was a question these calculi
left open.

\paragraph{Record calculi}
Harper and Pierce~\cite{harper1991record} presented a record
calculus based on symmetric concatenation with a type system that
tracks the absence of fields.
When two records define the same label, concatenation
is undefined (a type error); the calculus avoids same-label
composition rather than giving it meaning.
Cardelli~\cite{cardelli1992extensible}
studied extensible records with subtyping;
R\'emy~\cite{remy1989type} gave a type system for records and
variants in ML.
These calculi operate on \emph{flat} records (no nesting) and
treat records as \emph{data} (initial algebras): a record is a
finite map from labels to values, fully determined at construction
time.  Nested records, self-reference, and lazy observation---the
properties needed for records to serve as a computational
substrate---are outside their scope.

\paragraph{DOT calculus}
Amin et al.~\cite{amin2016dot} formalized path-dependent types in
the DOT calculus, the theoretical foundation of Scala's type system.
DOT paths navigate through objects to reach nested type members,
providing a rich dependent type structure.
DOT's self variable in the object constructor $\nu(x : T)\, d$
binds $x$ to a single object; when multiple inheritance routes
lead to the same enclosing scope, the resulting intersection type
is unrealizable and Scala rejects it at compile time
(Appendix~\ref{app:scala-multi-path}).
DOT includes the $\lambda$-calculus as a sub-language; removing it
while retaining path-dependent types would yield a calculus closer
to pure composition-based inheritance
(see Section~\ref{sec:future-work}).

\paragraph{Configuration languages}
CUE~\cite{cue2019} unifies types and values in a single lattice
where unification (\texttt{\&}) is commutative, associative, and
idempotent.
CUE's design was motivated by Google's Borg Configuration
Language (GCL), which used graph unification.
CUE's lattice includes scalar types with a conflict
semantics (unifying incompatible scalars yields $\bot$); whether
scalars are necessary for a configuration language, or whether
tree structure alone suffices, is an interesting design question.
Jsonnet~\cite{jsonnet} provides object inheritance via the
\texttt{+} operator with mixin semantics: composition is
\emph{not} commutative (the right-hand side wins on scalar
conflicts), and deep merging requires explicit opt-in (\texttt{+:}
syntax) on a per-field basis---so union mount semantics is
available but not the default.
Dhall~\cite{dhall2017} takes a functional approach: it is a typed
$\lambda$-calculus with records, where composition is a record merge
operator, not an inheritance mechanism.

\paragraph{Module systems and union mount semantics}
The NixOS module system~\cite{dolstra2008nixos,nixosmodules}
composes modules by \emph{recursively merging nested attribute sets},
not by linearization or method-level override---the same union mount
semantics that distinguishes tree-level composition from mixin and
trait composition.
When two modules define the same nested path, their subtrees are
merged rather than overridden.
The NixOS module system got nearly all of the high-level design
right: union mount composition, recursive self-reference, deferred
evaluation of modules, and a rich type-checking layer on top.
Its practical success is remarkable---the same mechanism powers
NixOS system configuration, Home
Manager~\cite{homemanager}, nix-darwin~\cite{nixdarwin},
flake-parts~\cite{flakeparts}, and dozens of other ecosystems,
collectively managing configurations of arbitrary complexity.
The one aspect that appears not to have been fully addressed is the
semantics of self-reference under multiple inheritance.
We attempted to implement Overlay-Calculus's qualified this
semantics within the NixOS module system but found that it
consistently diverged into infinite recursion.
This suggested that the module system's fixed-point evaluation,
while sufficient for its intended use cases, does not generalize
to the multi-path self-reference that recursive merging
naturally gives rise to---and motivated the coalgebraic
semantics of Section~\ref{sec:overlay-trees}.

\paragraph{SKI combinator calculus}
Sch\"onfinkel~\cite{schonfinkel1924} and
Curry~\cite{curry1958combinatory} showed that the $\lambda$-calculus
can be reformulated without bound variables using three
combinators (S, K, I).
SKI is function-free at the object level and Turing complete.
However, bracket abstraction translates between SKI and the
$\lambda$-calculus preserving computational structure, so the two
systems are isomorphic in terms of problem difficulty
(Section~\ref{sec:relationship}): what is hard in one remains hard
in the other.
Whether a function-free calculus can exhibit a genuine \emph{shift}
in problem difficulty---making some problems structurally easier than
in the $\lambda$-calculus, rather than merely encoding them
differently---is the question that motivates the comparison in
Section~\ref{sec:relationship}.

\section{Future Work}
\label{sec:future-work}

\selfcite{The Overlay language~\cite{mixin2025}}{The supplementary
implementation} is an executable implementation of Overlay-Calculus
that already goes beyond the untyped calculus presented here:
it includes compile-time checking that all references resolve to
valid paths in the composition, and a foreign-function interface (FFI)
that introduces scalar values from the host language.
The future work described below concerns the distance between this
implementation and a fully practical language---spanning both
theoretical foundations and library-level encodings.

\paragraph{Type system}
The Overlay language's existing compile-time checks verify that every
reference path resolves to a property that exists in the composed
result. Formalizing the soundness of these checks---proving that
well-typed programs do not produce dangling references at
runtime---is one direction of future work.
Such a formalization would relate to the DOT
calculus~\cite{amin2016dot} in a manner analogous to how
Overlay-Calculus relates to the $\lambda$-calculus: a Typed
Overlay-Calculus can be viewed as DOT without $\lambda$, retaining
path-dependent types while replacing functions with
inheritance-based composition.
A formal type system would be amenable to mechanization in proof
assistants (Coq, Agda) for verifying type safety, progress, and
preservation properties.

Beyond soundness of the existing checks, additional type system
features would strengthen the language.
A key example is \emph{totality checking}: verifying that a
composition provides implementations for all required slots, not
merely that references resolve.
In untyped Overlay-Calculus, writing $\mathrm{magnitude} \mapsto \{\}$
is purely documentary---it defines a structural slot but imposes no
constraint on what must fill it.
Totality checking would enforce such declarations statically,
rejecting compositions that leave required slots unfilled.

\paragraph{Standard library}
The remaining items concern the \emph{standard library}: they require
no extensions to the calculus or type system, but involve nontrivial
encodings within the existing framework.

Overlay-Calculus is \emph{open by default}: composition
can freely merge any two overlays, and a value may simultaneously
inhabit multiple constructors (e.g.,
$\{\mathrm{Zero},\; \mathrm{Odd},\; \mathrm{half} \mapsto \mathrm{Zero}\}$).
This is not a defect---it is the natural trie semantics of the
calculus, and the basis for solving the expression problem
(Section~\ref{sec:asymmetry}).
However, many operations (e.g., equality testing) assume that values
are \emph{linear}---inhabiting exactly one constructor.
The observer pattern (Appendix~\ref{app:church}) does not enforce
this: applied to a multi-constructor value, all callbacks fire and
their results are composed.

\emph{Schema validation} can be implemented at the library level
using existing primitives.
An observer can test whether a particular constructor is present,
returning a Boolean; a second Boolean dispatch then branches on the
result.
By chaining such tests, a factory can validate that a value matches
exactly one constructor and carries the required fields.
This does not restrict composition itself---it remains
unconstrained---but provides a way to detect invariant violations
before they propagate.

The same technique---observer returning Boolean, followed by Boolean
dispatch---yields \emph{closed pattern matching}.
The observer pattern of Appendix~\ref{app:church} is inherently
\emph{open}: new constructor cases can be added through composition.
Closed matching, where exactly one branch is taken, can be encoded as
a \emph{visitor chain}: a linked list of if-then-else nodes, each
testing one constructor and falling through on mismatch.
This is analogous to GHC.Generics' $\mathrm{(:+:)}$ sum
representation~\cite{magalhaes2010generic}, where each link
corresponds to one summand.
An important consequence is that such chains do \emph{not}
commute---they have a fixed order---and therefore cannot be extended
through open composition, which is the correct semantics for closed
dispatch.

The trie operations in Appendix~\ref{app:trie} are hardcoded for
binary natural number keys.
Since every overlay \emph{is} a trie (Section~\ref{sec:trie}) and insertion is
simply composition, only operations that cannot be expressed as
composition need explicit implementation: \emph{deletion},
\emph{dynamic lookup}, and \emph{prefix lookup}.
Generalizing to arbitrary key types requires each key factory to
provide two interfaces---\emph{SelectTrieChild} (select a subtrie by
constructor) and \emph{ReplaceTrieChild} (replace a subtrie by
constructor while preserving the rest)---corresponding to the getter
and setter of a lens~\cite{foster2007combinators} focused on the
constructor-determined child.
Prefix lookup is structurally analogous to equality testing: both
synchronously traverse a key (a single-path trie) alongside another
structure, dispatching at each level.
The difference is the return type---a Boolean for equality, a subtrie
for prefix lookup.

\bibliographystyle{ACM-Reference-Format}
\bibliography{mixin-calculus}

\appendix

\section{Trie Operations}
\label{app:trie}

This appendix gives the full constructions for the RAM machine
operations summarized in Section~\ref{sec:trie}.
Index the trie by binary natural numbers using three labels---$\mathrm{value}$
for the stored entry at a node, $\mathrm{at\_odd}$ and $\mathrm{at\_even}$
for the two subtrees corresponding to the bit structure of the key:
\begin{align*}
  \mathrm{Zero} &\;\longrightarrow\; \mathrm{value} \\
  \mathrm{Odd}(n) &\;\longrightarrow\; \mathrm{at\_odd},\;\text{then path for } n \\
  \mathrm{Even}(n) &\;\longrightarrow\; \mathrm{at\_even},\;\text{then path for } n
\end{align*}

\paragraph{Write (insertion)}
Inserting an entry with value $v$ at key $k$ is composing a singleton
trie whose nesting mirrors the bit structure of $k$.
For example, inserting at key $5 = \mathrm{Odd}(\mathrm{Even}(\mathrm{Zero}))$:
\[
  \mathrm{trie}' = \{\mathrm{trie},\;
  \mathrm{at\_odd} \mapsto \{\mathrm{at\_even} \mapsto \{\mathrm{value} \mapsto v\}\}\}
\]
Each composition creates a new immutable trie; the original is unchanged.

\paragraph{Read (static lookup)}
When the key is known statically, retrieving the entry at key $k$ is
reference-path navigation: the reference follows the same label
sequence that was used for insertion. For the same key~$5$:
\[
  \qualifiedthis{\mathrm{enclosing\_scope}}.\mathrm{trie}.\mathrm{at\_odd}.\mathrm{at\_even}.\mathrm{value}
\]
where $\mathrm{enclosing\_scope}$ is the qualified-this scope name
containing the trie definition.
The reference mechanism traverses the nested record structure---which
\emph{is} the trie---returning the value at the final node.

\paragraph{Read (dynamic lookup)}
When the key is a BinNat value constructed at runtime via
$\mathrm{Zero}$, $\mathrm{Odd}$, and $\mathrm{Even}$, the lookup
path must be computed dynamically. This is achieved by folding the
BinNat key into a \emph{Selector}---an overlay that, given a trie,
navigates to the appropriate node and returns the stored entry.
A Selector declares the trie shape and a result slot:
\[
  \mathrm{Selector} \mapsto \{
    \mathrm{trie} \mapsto \{
      \mathrm{value} \mapsto \{\},\;
      \mathrm{at\_odd} \mapsto \{\},\;
    \mathrm{at\_even} \mapsto \{\}\},\;
  \mathrm{result} \mapsto \{\}\}
\]
Three observer callbacks build Selectors bottom-up. These callbacks
($\mathrm{on\_zero}$, $\mathrm{on\_odd}$, $\mathrm{on\_even}$) are
interpretation points in the sense of Section~\ref{sec:cps-agnostic}: they can be filled
externally by an orchestrator (CPS interpretation) or composed locally
(direct interpretation), demonstrating the CPS-agnostic property.
The $\mathrm{on\_zero}$ callback returns a Selector that reads
$.\mathrm{value}$ from the trie:
\[
  \mathrm{lookup\_on\_zero} \mapsto \{
  \mathrm{Selector},\;
  \mathrm{result} \mapsto \qualifiedthis{\mathrm{lookup\_on\_zero}}.\mathrm{trie}.\mathrm{value}\}
\]
The $\mathrm{on\_odd}$ callback takes a Selector
(via the $\mathrm{argument}/\mathrm{result}$ encoding of
Section~\ref{sec:translation}) and returns a new Selector that navigates to
$.\mathrm{at\_odd}$, then delegates to the argument Selector:
\begin{align*}
  \mathrm{lookup\_on\_odd} &\mapsto \{
    \mathrm{argument} \mapsto \mathrm{Selector},\;
    \mathrm{result} \mapsto \{
      \mathrm{Selector},\;\\
      &\qquad
      \mathrm{applied} \mapsto \{
      \mathrm{argument},\;
      \mathrm{trie} \mapsto \qualifiedthis{\mathrm{lookup\_on\_odd}}.\mathrm{trie}.\mathrm{at\_odd}\},\\
      &\qquad
  \mathrm{result} \mapsto \mathrm{applied}.\mathrm{result}\}\}
\end{align*}
The $\mathrm{on\_even}$ callback is symmetric, navigating to
$.\mathrm{at\_even}$ instead.

The $\mathrm{Lookup}$ combinator folds a BinNat key with these
callbacks to obtain a Selector, then applies it to the trie:
\begin{align*}
  \mathrm{Lookup} &\mapsto \{\\
    &\quad \mathrm{key} \mapsto \qualifiedthis{\mathrm{trie\_module}}.\mathrm{BinNat},\\
    &\quad \mathrm{trie\_input} \mapsto \{\},\\
    &\quad \mathrm{applied\_key} \mapsto \{
      \mathrm{key},\;
      \mathrm{on\_zero} \mapsto \mathrm{lookup\_on\_zero},\;
      \mathrm{on\_odd} \mapsto \mathrm{lookup\_on\_odd},\;
    \mathrm{on\_even} \mapsto \mathrm{lookup\_on\_even}\},\\
    &\quad \mathrm{applied\_selector} \mapsto \{
    \mathrm{applied\_key}.\mathrm{result},\;
    \mathrm{trie} \mapsto \mathrm{trie\_input}\},\\
  &\quad \mathrm{result} \mapsto \mathrm{applied\_selector}.\mathrm{result}\}
\end{align*}
For example, looking up key $5 = \mathrm{Odd}(\mathrm{Even}(\mathrm{Zero}))$
folds into a Selector that navigates
$.\mathrm{at\_odd}.\mathrm{at\_even}.\mathrm{value}$---the same path
as the static reference, but computed from the key value.
The entire construction uses only records (with composition sources) and
references; no additional primitives are needed.

\paragraph{Delete}
Since composition is additive---it can only merge properties, never
remove them---deletion cannot be expressed as a single composition.
Instead, deletion \emph{reconstructs} the trie, copying every subtrie
except at the targeted key.

We fold the BinNat key into a \emph{Rebuilder}---an overlay that, given
an input trie, produces a new trie as its result.
A Rebuilder declares the trie shape on both its input and output:
\[
  \mathrm{Rebuilder} \mapsto \{
    \mathrm{trie} \mapsto \{\mathrm{value} \mapsto \{\},\; \mathrm{at\_odd} \mapsto \{\},\; \mathrm{at\_even} \mapsto \{\}\},\;
  \mathrm{result} \mapsto \{\mathrm{value} \mapsto \{\},\; \mathrm{at\_odd} \mapsto \{\},\; \mathrm{at\_even} \mapsto \{\}\}\}
\]
Three observer callbacks build Rebuilders bottom-up.
The $\mathrm{on\_zero}$ callback returns a Rebuilder that copies the
subtries but omits the value:
\[
  \mathrm{delete\_on\_zero} \mapsto \{
  \mathrm{Rebuilder},\;
  \mathrm{result} \mapsto \{
      \mathrm{at\_odd} \mapsto \qualifiedthis{\mathrm{delete\_on\_zero}}.\mathrm{trie}.\mathrm{at\_odd},\;
  \mathrm{at\_even} \mapsto \qualifiedthis{\mathrm{delete\_on\_zero}}.\mathrm{trie}.\mathrm{at\_even}\}\}\}
\]
The $\mathrm{result}.\mathrm{value}$ slot inherits only the empty
declaration from $\mathrm{Rebuilder}$, effectively deleting the entry.

The $\mathrm{on\_odd}$ callback takes a Rebuilder (the recursive
result for the subtrie) and returns a new Rebuilder that preserves
$\mathrm{value}$ and $\mathrm{at\_even}$, but replaces
$\mathrm{at\_odd}$ with the recursively rebuilt subtrie:
\begin{align*}
  \mathrm{delete\_on\_odd} &\mapsto \{
    \mathrm{argument} \mapsto \mathrm{Rebuilder},\;
    \mathrm{result} \mapsto \{
      \mathrm{Rebuilder},\;\\
      &\qquad
      \mathrm{applied} \mapsto \{
      \mathrm{argument},\;
      \mathrm{trie} \mapsto \qualifiedthis{\mathrm{delete\_on\_odd}}.\mathrm{trie}.\mathrm{at\_odd}\},\\
      &\qquad
      \mathrm{result} \mapsto \{
        \mathrm{value} \mapsto \qualifiedthis{\mathrm{delete\_on\_odd}}.\mathrm{trie}.\mathrm{value},\;
        \mathrm{at\_odd} \mapsto \mathrm{applied}.\mathrm{result},\;
        \mathrm{at\_even} \mapsto \qualifiedthis{\mathrm{delete\_on\_odd}}.\mathrm{trie}.\mathrm{at\_even}
  \}\}\}
\end{align*}
The $\mathrm{on\_even}$ callback is symmetric.

The $\mathrm{Delete}$ combinator folds a BinNat key with these
callbacks to obtain a Rebuilder, then applies it to the trie:
\begin{align*}
  \mathrm{Delete} &\mapsto \{\\
    &\quad \mathrm{key} \mapsto \qualifiedthis{\mathrm{trie\_module}}.\mathrm{BinNat},\\
    &\quad \mathrm{trie\_input} \mapsto \{\},\\
    &\quad \mathrm{applied\_key} \mapsto \{
      \mathrm{key},\;
      \mathrm{on\_zero} \mapsto \mathrm{delete\_on\_zero},\;
      \mathrm{on\_odd} \mapsto \mathrm{delete\_on\_odd},\;
    \mathrm{on\_even} \mapsto \mathrm{delete\_on\_even}\},\\
    &\quad \mathrm{applied\_rebuilder} \mapsto \{
    \mathrm{applied\_key}.\mathrm{result},\;
    \mathrm{trie} \mapsto \mathrm{trie\_input}\},\\
  &\quad \mathrm{result} \mapsto \mathrm{applied\_rebuilder}.\mathrm{result}\}
\end{align*}
Since composition is idempotent, the empty scaffolding left by the
Rebuilder schema merges harmlessly with any subsequent insertions.

\paragraph{Update}
Updating the entry at key $k$ to a new value $v$ combines deletion
and insertion.  Because $\mathrm{Delete}$ is a combinator whose
output lives in the \emph{result} property, one must first project
out the rebuilt trie before composing with the new singleton.
In ANF style:
\begin{align*}
  \mathrm{deleted} &\mapsto \{
    \mathrm{Delete},\;
    \mathrm{key} \mapsto k,\;
  \mathrm{trie\_input} \mapsto \mathrm{trie}\}\\
  \mathrm{result} &\mapsto \{
  \mathrm{deleted}.\mathrm{result},\;
  \mathrm{at\_odd} \mapsto \{\mathrm{at\_even} \mapsto
  \{\mathrm{value} \mapsto v\}\}\}
\end{align*}
where the second line uses key $5 = \mathrm{Odd}(\mathrm{Even}(\mathrm{Zero}))$
as a concrete example.
The projection $.\mathrm{result}$ is essential: $\mathrm{Delete}$
carries internal scaffolding ($\mathrm{key}$, $\mathrm{trie\_input}$,
$\mathrm{applied\_key}$, etc.), and only its $\mathrm{result}$
property holds the rebuilt trie.  This intermediate projection
prevents Update from being a single symmetric composition.

\section{Church Encoding of Standard Types}
\label{app:church}

This appendix demonstrates that standard data types can be encoded in
Overlay-Calculus without scalar types, using Church encoding. These
encodings serve as a proof of concept that a standard library can be
built entirely within Overlay-Calculus. Each encoding is presented as a
module overlay. In practical implementations, more efficient
representations (e.g., binary naturals) or FFI to host language
primitives would typically be used.
\selfcite{The implementation~\cite{mixin2025} includes}{The supplementary material includes} executable implementations of these
encodings with test cases for $\mathrm{Not}(\mathrm{True})$,
$\mathrm{And}(\mathrm{True}, \mathrm{True})$,
$\mathrm{Or}(\mathrm{False}, \mathrm{True})$, and natural number
addition, all verified against expected output snapshots.

\subsection{Boolean Module}

The boolean module contains a schema ($\mathrm{Boolean}$), constructors
($\mathrm{True}$, $\mathrm{False}$), and operations ($\mathrm{Not}$,
$\mathrm{And}$, $\mathrm{Or}$). All definitions are siblings within a
single module overlay.

\begin{align*}
  \{ \quad \mathrm{boolean} \mapsto \{ \quad
      \mathrm{Boolean} &\mapsto \{\mathrm{on\_true} \mapsto \{\},\;
        \mathrm{on\_false} \mapsto \{\},\;
      \mathrm{result} \mapsto \{\}\},
      \\[6pt]
      \mathrm{True} &\mapsto \{\mathrm{Boolean},\;
      \mathrm{result} \mapsto \qualifiedthis{\mathrm{True}}.\mathrm{on\_true}\},
      \\
      \mathrm{False} &\mapsto \{\mathrm{Boolean},\;
      \mathrm{result} \mapsto \qualifiedthis{\mathrm{False}}.\mathrm{on\_false}\},
      \\[6pt]
      \mathrm{Not} &\mapsto \{\mathrm{Boolean},\\
        &\qquad \mathrm{operand} \mapsto \mathrm{Boolean},\\
        &\qquad \mathrm{applied\_operand} \mapsto \{\mathrm{operand},\\
          &\qquad\qquad \mathrm{on\_true} \mapsto \qualifiedthis{\mathrm{Not}}.\mathrm{on\_false},\\
        &\qquad\qquad \mathrm{on\_false} \mapsto \qualifiedthis{\mathrm{Not}}.\mathrm{on\_true}\},\\
      &\qquad \mathrm{result} \mapsto \mathrm{applied\_operand}.\mathrm{result}\},
      \\[6pt]
      \mathrm{And} &\mapsto \{\mathrm{Boolean},\\
        &\qquad \mathrm{left} \mapsto \mathrm{Boolean},\\
        &\qquad \mathrm{right} \mapsto \mathrm{Boolean},\\
        &\qquad \mathrm{applied\_left} \mapsto \{\mathrm{left},\\
          &\qquad\qquad \mathrm{on\_true} \mapsto \mathrm{right},\\
        &\qquad\qquad \mathrm{on\_false} \mapsto \mathrm{False}\},\\
      &\qquad \mathrm{result} \mapsto \mathrm{applied\_left}.\mathrm{result}\},
      \\[6pt]
      \mathrm{Or} &\mapsto \{\mathrm{Boolean},\\
        &\qquad \mathrm{left} \mapsto \mathrm{Boolean},\\
        &\qquad \mathrm{right} \mapsto \mathrm{Boolean},\\
        &\qquad \mathrm{applied\_left} \mapsto \{\mathrm{left},\\
          &\qquad\qquad \mathrm{on\_true} \mapsto \mathrm{True},\\
        &\qquad\qquad \mathrm{on\_false} \mapsto \mathrm{right}\},\\
      &\qquad \mathrm{result} \mapsto \mathrm{applied\_left}.\mathrm{result}\}
  \quad \} \quad \}
\end{align*}

\paragraph{Reference explanation}
Within the $\mathrm{boolean}$ module, own properties such as
$\mathrm{Boolean}$, $\mathrm{True}$, $\mathrm{False}$, $\mathrm{Not}$,
$\mathrm{And}$, and $\mathrm{Or}$ are accessed via lexical references
(e.g., the composition source $\mathrm{Boolean}$ in each definition).
Qualified this is required in two situations:
\begin{itemize}
  \item \emph{Inherited properties.}
    Inside True's definition, $\qualifiedthis{\mathrm{True}}.\mathrm{on\_true}$
    requires qualified this because $\mathrm{on\_true}$ is inherited
    from Boolean via composition, not defined as an own property.
    Similarly, $\qualifiedthis{\mathrm{Not}}.\mathrm{on\_false}$ and
    $\qualifiedthis{\mathrm{Not}}.\mathrm{on\_true}$ access inherited callbacks.
  \item \emph{Variable shadowing.}
    Inside Not's $\mathrm{applied\_operand}$, the labels
    $\mathrm{on\_true}$ and $\mathrm{on\_false}$ are own properties
    of $\mathrm{applied\_operand}$ (with swapped values), so a
    lexical reference $\mathrm{on\_false}$ would resolve to the local
    definition rather than Not's inherited callback.
    Qualified this $\qualifiedthis{\mathrm{Not}}.\mathrm{on\_false}$ bypasses
    the shadowing.
\end{itemize}

\paragraph{Worked example}
Consider the expression
$\{\mathrm{boolean}.\mathrm{Not},\; \mathrm{operand} \mapsto \mathrm{boolean}.\mathrm{True},\;
\mathrm{on\_true} \mapsto A,\; \mathrm{on\_false} \mapsto B\}$
at the root scope level,
where $A$ and $B$ are arbitrary expressions.
The result is an object whose $\mathrm{result}$ label contains the same observable tree as $B$,
because $\mathrm{Not}$ swaps $\mathrm{on\_true}$ and $\mathrm{on\_false}$,
and $\mathrm{True}$ selects $\mathrm{on\_true}$,
which after swapping becomes $B$.

\subsection{Natural Number Module}

The natural number module contains a schema ($\mathrm{Nat}$),
constructors ($\mathrm{Zero}$, $\mathrm{Succ}$), and an operation
($\mathrm{Add}$).

\begin{align*}
  \{ \quad \mathrm{natural} \mapsto \{ \quad
      \mathrm{Nat} &\mapsto \{\mathrm{successor} \mapsto \{\mathrm{argument} \mapsto \{\},\;
        \mathrm{result} \mapsto \{\}\},\;
        \mathrm{zero} \mapsto \{\},\;
      \mathrm{result} \mapsto \{\}\},
      \\[6pt]
      \mathrm{Zero} &\mapsto \{\mathrm{Nat},\;
      \mathrm{result} \mapsto \qualifiedthis{\mathrm{Zero}}.\mathrm{zero}\},
      \\[6pt]
      \mathrm{Succ} &\mapsto \{\mathrm{Nat},\\
        &\qquad \mathrm{predecessor} \mapsto \mathrm{Nat},\\
        &\qquad \mathrm{applied\_predecessor} \mapsto \{\mathrm{predecessor},\\
          &\qquad\qquad \mathrm{successor} \mapsto \qualifiedthis{\mathrm{Succ}}.\mathrm{successor},\\
        &\qquad\qquad \mathrm{zero} \mapsto \qualifiedthis{\mathrm{Succ}}.\mathrm{zero}\},\\
        &\qquad \mathrm{applied\_successor} \mapsto \{\qualifiedthis{\mathrm{Succ}}.\mathrm{successor},\\
        &\qquad\qquad \mathrm{argument} \mapsto \mathrm{applied\_predecessor}.\mathrm{result}\},\\
      &\qquad \mathrm{result} \mapsto \mathrm{applied\_successor}.\mathrm{result}\},
      \\[6pt]
      \mathrm{Add} &\mapsto \{\mathrm{Nat},\\
        &\qquad \mathrm{augend} \mapsto \mathrm{Nat},\\
        &\qquad \mathrm{addend} \mapsto \mathrm{Nat},\\
        &\qquad \mathrm{applied\_addend} \mapsto \{\mathrm{addend},\\
          &\qquad\qquad \mathrm{successor} \mapsto \qualifiedthis{\mathrm{Add}}.\mathrm{successor},\\
        &\qquad\qquad \mathrm{zero} \mapsto \qualifiedthis{\mathrm{Add}}.\mathrm{zero}\},\\
        &\qquad \mathrm{applied\_augend} \mapsto \{\mathrm{augend},\\
          &\qquad\qquad \mathrm{successor} \mapsto \qualifiedthis{\mathrm{Add}}.\mathrm{successor},\\
        &\qquad\qquad \mathrm{zero} \mapsto \mathrm{applied\_addend}.\mathrm{result}\},\\
      &\qquad \mathrm{result} \mapsto \mathrm{applied\_augend}.\mathrm{result}\}
  \quad \} \quad \}
\end{align*}

\paragraph{Concrete example}
At the root scope level,
$\mathrm{one} \mapsto \{\mathrm{natural}.\mathrm{Succ},\; \mathrm{predecessor} \mapsto \mathrm{natural}.\mathrm{Zero}\}$.
Applying this with a Peano-style successor and zero:
$\{\mathrm{one},\; \mathrm{successor} \mapsto S,\; \mathrm{zero} \mapsto Z\}$
produces an object whose $\mathrm{result}$ label contains the same observable tree as
$\{S,\; \mathrm{argument} \mapsto Z.\mathrm{result}\}.\mathrm{result}$,
i.e., successor applied once to zero.
Here $S$ and $Z$ are arbitrary expressions representing
a successor operation and a zero value respectively.

\section{Multi-Path Self-Reference in Scala}
\label{app:scala-multi-path}

This appendix demonstrates that Scala~3 rejects the multi-path
self-reference pattern that Overlay-Calculus handles naturally.
Consider two objects that independently extend an outer class,
each providing its own copy of an inner trait:

\begin{verbatim}
class MyOuter:
  trait MyInner:
    def outer = MyOuter.this

object Object1 extends MyOuter
object Object2 extends MyOuter
object MyObjectA extends Object1.MyInner
                     with Object2.MyInner
\end{verbatim}

\noindent
Scala~3 rejects \texttt{MyObjectA} with the error:

\begin{verbatim}
trait MyInner is extended twice
object MyObjectA cannot be instantiated since
  it has conflicting base types
  Object1.MyInner and Object2.MyInner
\end{verbatim}

\noindent
The rejection is not a surface-level restriction but a consequence
of DOT's type-theoretic foundations~\cite{amin2016dot}.
In DOT, an object is constructed as $\nu(x : T)\, d$, where the
self variable~$x$ binds to a \emph{single} object.
\texttt{Object1.MyInner} and \texttt{Object2.MyInner} are distinct
path-dependent types, each constraining the outer self-reference
to a different object.
Their intersection requires \texttt{outer} to simultaneously
return \texttt{Object1} and \texttt{Object2}---but DOT's self
variable is single-valued, making this intersection unrealizable.

The equivalent Overlay-Calculus definition is:
\begin{align*}
  \{ \quad \mathrm{MyOuter} &\mapsto \{
    \mathrm{MyInner} \mapsto \{
    \mathrm{outer} \mapsto \qualifiedthis{\mathrm{MyOuter}}\}\}, \\
  \mathrm{Object1} &\mapsto \{\mathrm{MyOuter}\}, \\
  \mathrm{Object2} &\mapsto \{\mathrm{MyOuter}\}, \\
  \mathrm{MyObjectA} &\mapsto \{
    \mathrm{Object1}.\mathrm{MyInner},\;
  \mathrm{Object2}.\mathrm{MyInner}\}
  \quad \}
\end{align*}
This is well-defined in Overlay-Calculus.
Inside $\mathrm{MyInner}$, the reference
$\qualifiedthis{\mathrm{MyOuter}}$ has de~Bruijn index $n = 1$
(one scope level up from $\mathrm{MyInner}$ to $\mathrm{MyOuter}$).
When $\mathrm{MyObjectA}$ inherits from both
$\mathrm{Object1}.\mathrm{MyInner}$ and
$\mathrm{Object2}.\mathrm{MyInner}$,
the $\this$ function (equation~\ref{eq:this}) resolves
$\qualifiedthis{\mathrm{MyOuter}}$ by searching through
$\supers(\mathrm{MyObjectA})$ for overlay paths matching
$\mathrm{MyInner}$'s definition site.
It finds two composition-site paths---one through
$\mathrm{Object1}$ and one through $\mathrm{Object2}$---and
returns both.
Both paths lead to records that inherit from the same
$\mathrm{MyOuter}$, so querying
$\mathrm{MyObjectA}.\mathrm{outer}$ yields the
$\properties$ of $\mathrm{MyOuter}$ regardless of which
route is taken.
Since composition is idempotent, the two routes contribute the
same properties and no disambiguation is needed.

\section{Well-Definedness of the Semantic Functions}
\label{app:well-definedness}

This appendix proves that the mutually recursive equations
(\ref{eq:properties})--(\ref{eq:this}) have a unique least
fixed point, and therefore the semantics of
Section~\ref{sec:overlay-trees} is well-defined.

\subsection{The Product Lattice}

Fix an AST with its primitive functions $\ownproperties$ and
$\references$.
Let $\mathcal{L}$ denote the set of all labels and
$\mathcal{P}$ the set of all paths (finite sequences of labels).
Define the following domains, one for each semantic function:
\begin{align*}
  D_{\properties} &= \mathcal{P} \to \mathcal{P}(\mathcal{L})
  & &\text{(sets of labels)} \\
  D_{\supers} &= \mathcal{P} \to \mathcal{P}(\mathcal{P} \times \mathcal{P})
  & &\text{(sets of site--overlay pairs)} \\
  D_{\overlays} &= \mathcal{P} \to \mathcal{P}(\mathcal{P})
  & &\text{(sets of paths)} \\
  D_{\bases} &= \mathcal{P} \to \mathcal{P}(\mathcal{P})
  & &\text{(sets of paths)} \\
  D_{\resolve} &= (\mathcal{P} \times \mathcal{P} \times \mathbb{N}
  \times \mathcal{L}^*) \to \mathcal{P}(\mathcal{P})
  & &\text{(sets of paths)} \\
  D_{\this} &= (\mathcal{P}(\mathcal{P}) \times \mathcal{P} \times \mathbb{N})
  \to \mathcal{P}(\mathcal{P})
  & &\text{(sets of paths)}
\end{align*}
Each $D_i$ is a complete lattice under the pointwise subset
ordering: $f \sqsubseteq g$ iff $f(x) \subseteq g(x)$ for all $x$.
The product
$D = D_{\properties} \times D_{\supers} \times D_{\overlays}
\times D_{\bases} \times D_{\resolve} \times D_{\this}$
is a complete lattice under the componentwise ordering, with
bottom element $\bot = (\lambda x.\,\varnothing, \ldots,
\lambda x.\,\varnothing)$.

\subsection{The Operator}

Equations~(\ref{eq:properties})--(\ref{eq:this}) define a
function
$F : D \to D$
that takes a tuple of candidate interpretations
$(\properties, \supers, \overlays, \bases, \resolve, \this)$
and produces a new tuple by evaluating the right-hand side of
each equation.
The transitive closure $\bases^*$ appearing in
equation~(\ref{eq:supers}) is derived from $\bases$: for
any fixed $\bases$, the set $\bases^*(p)$ is defined as the
least fixed point of the monotone operator
$X \mapsto \{p\} \cup \bigcup_{q \in X} \bases(q)$
on $\mathcal{P}(\mathcal{P})$.
If $\bases \sqsubseteq \bases'$ (pointwise), then
$\bases^* \sqsubseteq \bases'^*$ (pointwise), since enlarging the
one-step relation can only enlarge the transitive closure.

The $\this$ function involves a recursion on the de~Bruijn
index~$n$.
Since $n$ decreases by one at each step and is a non-negative
integer, this recursion terminates for any fixed interpretation
of $\supers$.
The result of $\this(S, p_{\mathrm{def}}, n)$ for all valid
$(S, p_{\mathrm{def}}, n)$ is therefore well-defined as a
function of $\supers$, and it remains to show that it is monotone
in $\supers$.

\subsection{Monotonicity}

\begin{proposition}\label{prop:monotone}
  The operator $F$ is monotone:
  if $\vec{d} \sqsubseteq \vec{d}'$ in $D$,
  then $F(\vec{d}) \sqsubseteq F(\vec{d}')$.
\end{proposition}

\begin{proof}
It suffices to show that each component of $F$ is monotone in every
argument, i.e., that enlarging any of the input interpretations
(in the $\subseteq$ ordering) can only enlarge the output.
We verify this by inspecting the right-hand side of each equation
and confirming that every occurrence of a mutually defined function
appears in a \emph{positive} position---as the domain of an
existential quantifier in a set
comprehension~\cite{aczel1977inductive}.

\paragraph{Equation~(\ref{eq:properties}): $\properties$}
$\properties(p) =
\bigl\{\, \ell \bigm|
(\_, p_{\mathrm{overlay}}) \in \supers(p),\;
\ell \in \ownproperties(p_{\mathrm{overlay}})
\,\bigr\}$.
The function $\supers$ appears as the set being iterated
over ($\in \supers(p)$).
The predicate $\ell \in \ownproperties(\cdot)$ involves only
the AST primitive $\ownproperties$, not any mutually defined
function.
Enlarging $\supers(p)$ can only add pairs, hence can only add
labels to the result.
\emph{Positive in $\supers$.}

\paragraph{Equation~(\ref{eq:supers}): $\supers$}
$\supers(p) =
\bigl\{\, (\init(p_{\mathrm{base}}), p_{\mathrm{overlay}}) \bigm|
p_{\mathrm{base}} \in \bases^*(p),\;
p_{\mathrm{overlay}} \in \overlays(p_{\mathrm{base}})
\,\bigr\}$.
Both $\bases^*$ and $\overlays$ appear as sets being iterated
over.
As noted above, $\bases^*$ is monotone in $\bases$.
Enlarging either $\bases$ or $\overlays$ can only add elements to the
result.
\emph{Positive in $\bases$ and $\overlays$.}

\paragraph{Equation~(\ref{eq:overlays}): $\overlays$}
For $p \neq ()$:
$\overlays(p) = \{p\} \cup
\bigl\{\, p_{\mathrm{branch}} \snoc \last(p) \bigm|
(\_, p_{\mathrm{branch}}) \in \supers(\init(p)),\;
\last(p) \in \ownproperties(p_{\mathrm{branch}})
\,\bigr\}$.
The function $\supers$ appears as the set being iterated over.
The filtering condition $\last(p) \in \ownproperties(\cdot)$
involves only the AST primitive.
Enlarging $\supers$ can only add branches, hence can only add paths
to the result.
\emph{Positive in $\supers$.}

\paragraph{Equation~(\ref{eq:bases}): $\bases$}
$\bases(p) =
\bigl\{\, p_{\mathrm{target}} \bigm|
p_{\mathrm{overlay}} \in \overlays(p),\;
(n, \ell_{\mathrm{down},*}) \in \references(p_{\mathrm{overlay}}),\;
p_{\mathrm{target}} \in \resolve(\ldots)
\,\bigr\}$.
Both $\overlays$ and $\resolve$ appear as sets being iterated
over.
The function $\references$ is an AST primitive.
Enlarging either $\overlays$ or $\resolve$ can only add targets to
the result.
\emph{Positive in $\overlays$ and $\resolve$.}

\paragraph{Equation~(\ref{eq:resolve}): $\resolve$}
$\resolve(\ldots) =
\bigl\{\,
p_{\mathrm{current}} \snoc \ell_{\mathrm{down},1} \snoc \cdots
\bigm|
p_{\mathrm{current}} \in
\this(\{p_{\mathrm{site}}\}, \init(p_{\mathrm{def}}), n)
\,\bigr\}$.
The function $\this$ appears as the set being iterated over.
Enlarging $\this$ can only add paths to the result.
\emph{Positive in $\this$.}

\paragraph{Equation~(\ref{eq:this}): $\this$}
For $n > 0$:
$\this(S, p_{\mathrm{def}}, n) =
\this(S', \init(p_{\mathrm{def}}), n - 1)$
where
$S' = \bigl\{\, p_{\mathrm{site}} \bigm|
p_{\mathrm{current}} \in S,\;
(p_{\mathrm{site}}, p_{\mathrm{overlay}}) \in
\supers(p_{\mathrm{current}}),\;
p_{\mathrm{overlay}} = p_{\mathrm{def}}
\,\bigr\}$.
The function $\supers$ appears as the set being iterated over.
The filtering condition $p_{\mathrm{overlay}} = p_{\mathrm{def}}$
is an equality test on path data, not involving any mutually
defined function.
Enlarging $\supers$ can only enlarge $S'$, and by induction on~$n$
(the base case $n = 0$ returns $S$ unchanged), the recursive call
is monotone in $S'$.
\emph{Positive in $\supers$.}

\medskip\noindent
In summary, every mutually defined function appears on the
right-hand side of every equation only inside the pattern
$x \in f(\ldots)$ within a set comprehension---i.e., as the
domain of an existential quantifier.
No complement, set difference, or negated membership test
appears in any equation.
Therefore $F$ is a monotone operator on the complete lattice $D$.
\end{proof}

\subsection{Existence of the Least Fixed Point}

\begin{theorem}\label{thm:well-defined}
  The semantic functions
  $\properties$, $\supers$, $\overlays$, $\bases$, $\resolve$,
  $\this$ are well-defined as the least fixed point of~$F$.
\end{theorem}

\begin{proof}
By Proposition~\ref{prop:monotone}, $F$ is monotone on the
complete lattice~$D$.
By the Knaster--Tarski theorem~\cite{tarski1955lattice}, $F$ has
a least fixed point $\vec{d}^* = \bigsqcup_{n \ge 0} F^n(\bot)$,
where $\bot$ assigns the empty set to every input.
The components of $\vec{d}^*$ are the semantic functions of
Section~\ref{sec:overlay-trees}.

Concretely, the least fixed point is the union of the finite
approximation chain:
$\bot \sqsubseteq F(\bot) \sqsubseteq F^2(\bot) \sqsubseteq \cdots$.
A membership $\ell \in \properties(p)$ holds in $\vec{d}^*$
if and only if it appears at some finite stage $F^k(\bot)$,
which corresponds to a finite derivation tree using the
equations.
When no finite derivation exists, the membership is absent from
the least fixed point and the query is undefined---the
analogue of divergence.
\end{proof}

\end{document}
