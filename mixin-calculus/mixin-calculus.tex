%%
%% Onward! submission using ACM SIGPLAN acmart format
%%
\documentclass[manuscript,anonymous,review,10pt]{acmart}

\AtBeginDocument{%
\providecommand\BibTeX{{Bib\TeX}}}

%% Disable ACM-specific metadata for submission
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

\usepackage{mathtools}

%% Conditional citation: hide self-citations under anonymous review
\newcommand{\selfcite}[2]{%
  \if@ACM@anonymous{#2}\else{#1}\fi
}

\DeclareMathOperator{\Class}{Class}
\DeclareMathOperator{\Mixin}{Mixin}
\DeclareMathOperator{\Object}{Object}
\DeclareMathOperator{\Constructor}{Constructor}
\DeclareMathOperator{\eval}{evaluate}
\DeclareMathOperator{\bind}{bind}
\DeclareMathOperator{\dom}{dom}
\newcommand{\up}{\uparrow}

\begin{document}

\title{MixinCalculus}

\author{Bo Yang}
\affiliation{%
  \institution{Figure AI Inc.}
  \city{San Jose}
  \state{California}
  \country{USA}
}
\email{yang-bo@yang-bo.com}
\thanks{This work was conducted independently prior to the author's employment at Figure AI.}

\begin{abstract}
  Just as the $\lambda$-calculus uses three primitives (abstraction,
  application, variable) as the foundation of functional programming,
  MixinCalculus uses three primitives (record, reference, composition)
  as the foundation of declarative programming. Unlike the $\lambda$-calculus,
  which requires first-class functions, or Turing machines, which require
  mutable state, MixinCalculus is purely declarative and function-free,
  yet Turing complete. Composition ($\oplus$) is commutative, idempotent,
  and associative---the linearization problem familiar from traditional
  mixin and trait systems simply does not arise. We demonstrate Turing
  completeness by giving a straightforward translation from the
  $\lambda$-calculus into MixinCalculus, showing that function application
  is derivable from symmetric mixin composition.
  Programs are inherently in A-normal form; unlike compiler-internal ANF
  which targets a fixed monad, MixinCalculus ANF supports dependency
  injection, making programs CPS-agnostic---the same code serves as either
  continuation-passing or direct-style depending on assembly.
  Records serve as tries, making MixinCalculus an immutable analogue of
  the RAM machine. These observations suggest MixinCalculus as a computational model
  for declarative programming, with applications to configuration languages,
  mixin-based object systems, composable effect systems, and modular software
  architectures.
\end{abstract}

\begin{CCSXML}
  <ccs2012>
  <concept>
  <concept_id>10003752.10010124.10010131.10010133</concept_id>
  <concept_desc>Theory of computation~Denotational semantics</concept_desc>
  <concept_significance>100</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10010124.10010125.10010128</concept_id>
  <concept_desc>Theory of computation~Object oriented constructs</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10010124.10010125.10010127</concept_id>
  <concept_desc>Theory of computation~Functional constructs</concept_desc>
  <concept_significance>300</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10010124.10010125.10010129</concept_id>
  <concept_desc>Theory of computation~Program schemes</concept_desc>
  <concept_significance>100</concept_significance>
  </concept>
  <concept>
  <concept_id>10011007.10011006.10011039</concept_id>
  <concept_desc>Software and its engineering~Formal language definitions</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10011007.10011006.10011008.10011009.10011019</concept_id>
  <concept_desc>Software and its engineering~Extensible languages</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10011007.10011006.10011008.10011009.10011011</concept_id>
  <concept_desc>Software and its engineering~Object oriented languages</concept_desc>
  <concept_significance>100</concept_significance>
  </concept>
  </ccs2012>
\end{CCSXML}

\ccsdesc[100]{Theory of computation~Denotational semantics}
\ccsdesc[500]{Theory of computation~Object oriented constructs}
\ccsdesc[300]{Theory of computation~Functional constructs}
\ccsdesc[100]{Theory of computation~Program schemes}
\ccsdesc[500]{Software and its engineering~Formal language definitions}
\ccsdesc[500]{Software and its engineering~Extensible languages}
\ccsdesc[100]{Software and its engineering~Object oriented languages}

\maketitle

\section{Introduction}

Declarative and configuration languages are ubiquitous in modern software
engineering. Systems such as NixOS modules~\cite{dolstra2008nixos,nixosmodules},
Jsonnet~\cite{jsonnet}, Hydra~\cite{hydra2023}, CUE~\cite{cue2019}, Dhall~\cite{dhall2017},
Kustomize, and JSON Patch (RFC~6902) all provide mechanisms for composing
structured data through inheritance or overlay. Among these, the NixOS
module system stands out: its recursive attribute set merging with
fixed-point semantics and deferred modules~\cite{nixosmodules} achieves
remarkable expressiveness in practice, and the mechanism has been adopted
well beyond NixOS itself---Home Manager~\cite{homemanager} manages user
environments across platforms, nix-darwin~\cite{nixdarwin} brings
declarative configuration to macOS, disko~\cite{disko} handles disk
partitioning, flake-parts~\cite{flakeparts} structures Nix flakes,
dream2nix~\cite{dream2nix} automates multi-language packaging,
devenv~\cite{devenv} composes developer environments, and
KubeNix~\cite{kubenix} and nixidy~\cite{nixidy} manage Kubernetes
clusters---all built on the same module system. Yet no computational
theory explains \emph{why} this mechanism is so powerful.

The $\lambda$-calculus serves as the foundational computational model for
functional programming. No analogous calculus exists for declarative
programming. This gap matters because the two paradigms differ in
fundamental ways. Configuration languages are inherently declarative:
their values are \emph{immutable} and they have \emph{no first-class
functions}. At first glance, Turing completeness appears incompatible
with these constraints. The three classical models of computation each
violate at least one of them:

\begin{center}
  \begin{tabular}{lccc}
    \textbf{Model} & \textbf{Turing complete} & \textbf{Immutable} & \textbf{No $\lambda$} \\
    \hline
    Turing Machine     & $\checkmark$ & $\times$     & $\checkmark$ \\
    $\lambda$-calculus & $\checkmark$ & $\checkmark$ & $\times$ \\
    RAM Machine        & $\checkmark$ & $\times$     & $\checkmark$ \\
  \end{tabular}
\end{center}

\noindent
The Turing Machine and RAM Machine require mutable state;
the $\lambda$-calculus requires first-class functions.
There was no known computational model that is simultaneously
Turing complete, immutable, and function-free. Yet the NixOS module
system already demonstrates that this gap can be bridged in practice:
its inheritance-based composition over recursive records, without
explicit functions, is expressive enough to configure entire operating
systems.

Conventionally, the value domain of configuration languages is assumed
to consist of finite, well-founded structures---initial algebras in the
sense of universal algebra. We challenge this assumption: configuration
values are better understood as lazily observable, possibly infinite
structures---formally, F-coalgebras~\cite{rutten2000universal}---where
semantics is determined by the observer and a finite prefix suffices
for any finite observation. This is not merely a theoretical
distinction: the \texttt{nixpkgs} package
collection~\cite{dolstra2006purely}---over 100{,}000
packages---is a lazy-evaluated F-coalgebra in practice, allowing any
single package to be evaluated without materializing the entire set.

This paper provides the missing theoretical foundation. We present
\textbf{MixinCalculus}, a minimal calculus that distills the essence of
this mechanism into three constructs---record literals, references,
and composition ($\oplus$)---without functions or let-bindings.
A key observation is that
\emph{function application admits a straightforward translation into inheritance}:
a $\lambda$-abstraction corresponds to a record with an
$\mathrm{argument}$ slot and a $\mathrm{result}$ slot, and function
application corresponds to composing the function record with a record
that supplies the argument. This translation demonstrates that MixinCalculus
subsumes the $\lambda$-calculus and is therefore Turing complete.
This translation reveals an \emph{asymmetry}:
while embedding the $\lambda$-calculus into MixinCalculus is trivial,
the reverse is non-trivial because MixinCalculus provides primitive
operations---self-referential records, open recursion, symmetric
composition---that have no direct counterparts in the $\lambda$-calculus.
Moreover, MixinCalculus naturally encodes random-access memory:
records are tries, and composition is trie union, yielding an
immutable analogue of the RAM machine
(Section~\ref{sec:trie}).
This asymmetry suggests that MixinCalculus is not merely a
syntactic variant of the $\lambda$-calculus but captures
different computational patterns.

A further observation concerns the relationship between MixinCalculus and
continuation-passing style (CPS). Because every intermediate result in
MixinCalculus has a name, programs are inherently in A-normal
form~\cite{flanagan1993essence}. However, unlike ANF in functional
language compilers---which targets a fixed monad (typically the identity
monad~\cite{moggi1991notions}) and cannot express CPS
transformations---MixinCalculus ANF supports dependency injection through
empty record slots. This makes programs \emph{CPS-agnostic}: the same
code can be interpreted as continuation-passing (when slots are filled by
an external orchestrator) or as direct-style (when slots are composed
locally). From a category-theoretic perspective, this means abstract
interfaces and concrete implementations are syntactically
identical---only the assembly strategy differs. The $\lambda$-calculus
lacks this flexibility: converting between CPS and direct style requires
an explicit program transformation~\cite{plotkin1975callbyname,sabry1993reasoning}.

As a demonstration of this expressiveness, we port the Expression
Problem~\cite{wadler1998expression} solution of Wang and
Oliveira~\cite{wang2016trivially} from Scala (whose type system rests
on the DOT calculus~\cite{amin2016dot}) to MixinCalculus. The resulting
solution is even more concise than the original, despite MixinCalculus
having only three primitives whereas DOT is a substantially larger
system.

Another observation concerns the linearization problem that has long plagued
mixin-based systems~\cite{bracha1990mixin,c3linearization}. In traditional
mixin or trait calculi~\cite{scharli2003traits,ducasse2006traits}, composing
mixins that define the same field raises conflicts that must be resolved by
a linearization order. In MixinCalculus, because there are no scalar values,
the observable behavior at every node is solely \emph{key presence}---a set
of labels. Composition ($\oplus$) is therefore commutative, idempotent, and
associative. The linearization problem does not arise---not because it is
resolved, but because it does not exist.

Just as the $\lambda$-calculus uses three primitives (abstraction,
application, variable) to serve as the foundation of functional
programming, MixinCalculus uses three primitives (record, reference,
composition) to serve as the foundation of declarative programming.

All constructions in this paper have been implemented and tested in
MIXIN, an executable implementation of MixinCalculus using YAML syntax,
\selfcite{available as open source~\cite{mixin2025}}{included as supplementary material}. The implementation comprises a core
evaluator, a standard library of Church-encoded data types, and a test
suite covering every example in this paper: the Expression Problem
solution (Section~\ref{sec:expression-problem}), escape and multi-exit
continuations (Section~5.3), the Selector and Rebuilder combinators for
dynamic trie operations (Appendix~\ref{app:trie}), and Church-encoded
booleans and natural numbers (Appendix~\ref{app:church}). All tests are
mechanically verified against expected output snapshots.

\paragraph{Contributions.}
\begin{itemize}
  \item We present MixinCalculus, a minimal computational model for
    declarative programming that contains only mixin constructs (record,
    reference, composition) and no functions or scalar types.
  \item We observe that composition ($\oplus$) is commutative, idempotent,
    and associative, and provide an intuitive explanation for why this
    holds. The linearization problem inherent in prior mixin and trait
    calculi simply does not arise.
  \item We give a translation from the $\lambda$-calculus (with
    De~Bruijn indices) to MixinCalculus, demonstrating that MixinCalculus
    subsumes the $\lambda$-calculus and is Turing complete.
    As a corollary, standard data types (booleans, natural numbers)
    can be Church-encoded without scalars (Appendix~\ref{app:church}).
  \item We show that MixinCalculus programs are CPS-agnostic: the same code
    can be interpreted as either continuation-passing or direct-style depending
    on assembly strategy, in contrast to the $\lambda$-calculus where CPS
    conversion is an explicit program transformation.
\end{itemize}

\paragraph{Informal example.}\label{sec:expression-problem}
The Expression Problem~\cite{wadler1998expression}
asks how to extend a data type with both new cases and new operations,
without modifying existing code.
In a typed setting this additionally requires static type safety;
MixinCalculus is untyped, so we focus on the extensibility aspect.
Suppose a standard library provides a $\mathrm{binnat}$ module for
binary natural arithmetic (see Appendix).
We define an expression language with an evaluation operation:
\begin{align*}
  \{ \quad \mathrm{expression} &\mapsto \{
      \mathrm{Constant} \mapsto \{\mathrm{magnitude} \mapsto \{\}\},\;
      \mathrm{Addition} \mapsto \{\mathrm{left} \mapsto \{\},\;
    \mathrm{right} \mapsto \{\}\}\}, \\[4pt]
    \mathrm{evaluation} &\mapsto \{
      \mathrm{Constant} \mapsto \up^1.\mathrm{expression}.\mathrm{Constant}
      \oplus \{\mathrm{outcome} \mapsto \up^0.\mathrm{magnitude}\}, \\
      &\qquad \mathrm{Addition} \mapsto
      \up^1.\mathrm{expression}.\mathrm{Addition} \oplus \{ \\
        &\qquad\qquad
        \mathrm{left\_outcome} \mapsto \up^0.\mathrm{left}.\mathrm{outcome},\\
        &\qquad\qquad
        \mathrm{right\_outcome} \mapsto \up^0.\mathrm{right}.\mathrm{outcome},\\
        &\qquad\qquad
        \mathrm{sum} \mapsto \up^2.\mathrm{binnat}.\mathrm{Addition}
        \oplus \{\mathrm{augend} \mapsto \up^1.\mathrm{left\_outcome},\;
        \mathrm{addend} \mapsto \up^1.\mathrm{right\_outcome}\}, \\
        &\qquad\qquad
    \mathrm{outcome} \mapsto \up^0.\mathrm{sum}.\mathrm{outcome}\}\},\\[4pt]
    \mathrm{binnat} &\mapsto \{
      \mathrm{Addition} \mapsto
      \{\mathrm{augend} \mapsto \{\},\;
        \mathrm{addend} \mapsto \{\},\;
    \mathrm{outcome} \mapsto \{\}\}\}
  \quad \}
\end{align*}
A new operation (e.g., display) is added by defining a new
module that inherits from the same $\mathrm{expression}$ schemas:
\begin{align*}
  \mathrm{display} \mapsto \{
    \mathrm{Constant} &\mapsto \up^1.\mathrm{expression}.\mathrm{Constant}
    \oplus \{\mathrm{representation} \mapsto \up^0.\mathrm{magnitude}\},\\
    \mathrm{Addition} &\mapsto \up^1.\mathrm{expression}.\mathrm{Addition}
    \oplus \{\mathrm{representation} \mapsto \{
        \mathrm{left} \mapsto \up^1.\mathrm{left}.\mathrm{representation},\;
  \mathrm{right} \mapsto \up^1.\mathrm{right}.\mathrm{representation}\}\}\}
\end{align*}
A new case (e.g., negation) is added with its operation handlers
and an empty API for the arithmetic primitive:
\begin{align*}
  \mathrm{negation} &\mapsto \{
    \mathrm{Negation} \mapsto
  \{\mathrm{operand} \mapsto \{\}\}\}, \\
  \mathrm{negation\_evaluation} &\mapsto \{
    \mathrm{Negation} \mapsto
    \up^1.\mathrm{negation}.\mathrm{Negation} \oplus \{\\
      &\qquad
      \mathrm{operand\_outcome} \mapsto \up^0.\mathrm{operand}.\mathrm{outcome},\\
      &\qquad
      \mathrm{negated} \mapsto \up^2.\mathrm{binnat}.\mathrm{Negation}
      \oplus \{\mathrm{operand} \mapsto \up^1.\mathrm{operand\_outcome}\},\\
      &\qquad
  \mathrm{outcome} \mapsto \up^0.\mathrm{negated}.\mathrm{outcome}\}\}, \\
  \mathrm{binnat} &\mapsto \{
    \mathrm{Negation} \mapsto
    \{\mathrm{operand} \mapsto \{\},\;
  \mathrm{outcome} \mapsto \{\}\}\}
\end{align*}
All modules compose freely via $\oplus$; none requires modification of
existing definitions.
A complete executable version of this example---including both the
evaluation and display operations, a negation extension, and their free
composition---is \selfcite{available in the implementation~\cite{mixin2025}}{included in the supplementary material}, along with test
cases verifying evaluation and display for nested expressions mixing old
and new cases.

Note that $\mathrm{magnitude} \mapsto \{\}$ in $\mathrm{Constant}$
resembles a type annotation but is purely structural in MixinCalculus:
the evaluator works as long as the required fields appear somewhere in
the composition chain, regardless of any schema declarations.

\section{Syntax}

Let $e$ denote an expression.
Let $\ell$ denote a label (property name).
Let $n$ denote a non-negative integer (scope depth).
Let $k$ denote a non-negative integer (path length).

\begin{align*}
  e \quad ::= \quad & \{\ell_1 \mapsto e_1,\; \ldots,\; \ell_n \mapsto e_n\}
  && \text{(record, } n \ge 0\text{)} \\
  \mid\quad & \up^n.\ell_1.\ell_2\ldots\ell_k
  && \text{(reference, } k \ge 0\text{)} \\
  \mid\quad & e_1 \oplus e_2
  && \text{(composition)}
\end{align*}

The $\mapsto$ in $\{\ell \mapsto e\}$ defines a mixin property, not a let-binding.
There is no variable binding in MixinCalculus.
In pursuit of a minimal computational model, MixinCalculus contains no
scalar types. This does not limit computational power: just as the
$\lambda$-calculus can encode booleans and natural numbers via Church
encoding, so can MixinCalculus (Appendix~\ref{app:church}). Practical
implementations built on MixinCalculus may include scalars and a
foreign-function interface; this does not affect the analysis in this
paper, as scalars can be treated as opaque sets whose composition
remains commutative and idempotent.

\paragraph{Scope levels.}
The notation $\up^n$ follows De~Bruijn indices~\cite{debruijn1972lambda}.
A new scope level is created at each $\{\ldots\}$ (record literal).
The scope contains all properties of that mixin, including those introduced by $\oplus$.
In particular, $\{a \mapsto \{\}\} \oplus \{b \mapsto \{\}\}$ is a single mixin whose scope
contains both $a$ and $b$.
The operator $\oplus$ does not create additional scope levels.

\begin{itemize}
  \item $\up^0$ refers to the innermost enclosing $\{\ldots\}$.
  \item $\up^1$ refers to the next enclosing $\{\ldots\}$.
  \item $\up^n.\ell$ indexes into the scope chain at depth $n$, then projects property $\ell$.
\end{itemize}

\section{Semantic Domain}

\paragraph{Class.}
A multimap from labels to constructor lists, analogous to a class or trait.
A $\Class$ is not yet bound to self.
\[
  \Class = \ell \rightharpoonup \Constructor^*
\]

\paragraph{Constructor.}
A single $\{\ldots\}$ definition bound to its captured lexical scope.
A $\Constructor$ takes a single $\Object$ (the parent's self, after all merges) and returns a $\Class$.
Multiple constructors under the same label arise from merging via $\oplus$.
\[
  \Constructor = \Object \to \Class
\]

\paragraph{Mixin.}
A $\Class$ paired with its evaluated $\Object$.
This is the value at each node of the result.
\[
  \Mixin = (\Class, \Object)
\]

\paragraph{Object.}
The result of evaluating a $\Class$.
Each child is a $\Mixin$.
\[
  \Object = \ell \rightharpoonup \Mixin
\]

The only externally observable fact is key presence: $\ell \in \dom(\Object_0)$
for an $\Object$ named $\Object_0$.

\paragraph{Scope chain.}
The scope chain $\rho$ is an ordered list of $\Mixin$ values,
with index~0 being the innermost scope:
\[
  \rho = [\Mixin_0, \Mixin_1, \ldots]
  = [(\Class_0, \Object_0),\; (\Class_1, \Object_1),\; \ldots]
\]

\section{Semantics}

\paragraph{Composition ($\oplus$) on Classes.}
For each label $\ell$, concatenate the constructor lists:
\[
  (\Class_1 \oplus \Class_2)(\ell) = \Class_1(\ell) \mathbin{+\!\!+} \Class_2(\ell)
\]
Properties of $\oplus$: commutative, idempotent, associative.
The identity element is the empty class $\Class_\varnothing$
where $\Class_\varnothing(\ell) = []$ for all $\ell$.

\medskip\noindent\textit{Intuition.}\quad
List concatenation is not commutative.
However, $\eval$ calls all constructors with the \emph{same} $\Object_{\mathrm{self}}$
and merges results via $\oplus$ recursively.
To see why commutativity holds, observe that at every leaf the only
observable is key presence---a set of labels.
Since there are no scalars, the only observable at any node is which keys exist.
Set union is commutative and idempotent:
$\{a,b\} \cup \{b,c\} = \{b,c\} \cup \{a,b\}$ and $S \cup S = S$.
The observable tree is therefore invariant under reordering or deduplication of constructors.

Since duplicate constructors produce the same observable result,
implementations may deduplicate constructors (e.g., by source location)
to avoid the exponential blowup from diamond inheritance.

\paragraph{Evaluate.}
$\eval : \Class \to \Object$.

Let $\Class_{\mathrm{input}}$ be the input class.
Then $\eval(\Class_{\mathrm{input}}) = \Object_{\mathrm{self}}$ where:
\[
  \Object_{\mathrm{self}}(\ell) = (\Class_\ell,\; \eval(\Class_\ell))
  \quad\text{with}\quad
  \Class_\ell = \bigoplus_{\Constructor_i \in \Class_{\mathrm{input}}(\ell)} \Constructor_i(\Object_{\mathrm{self}})
\]
for all $\ell \in \dom(\Class_{\mathrm{input}})$,
where $\Constructor_i$ ranges over the constructors under label $\ell$.
This is a fixed point: $\Object_{\mathrm{self}}$ appears in its own definition.
All constructors under label $\ell$ are called with $\Object_{\mathrm{self}}$,
their results merged via $\oplus$,
then the merged $\Class$ is evaluated.
Each child entry is a $\Mixin = (\Class_\ell, \eval(\Class_\ell))$.

\paragraph{Bind.}
$\bind : (e, \rho) \to \Class$,
where $e$ is an expression and $\rho$ is a scope chain.

\begin{itemize}
  \item \textbf{Record:}
    $\bind(\{\ell_1 \mapsto e_1, \ldots, \ell_n \mapsto e_n\},\; \rho) = \Class_{\mathrm{record}}$
    where
    \[
      \Class_{\mathrm{record}}(\ell_i) = \bigl[\lambda \Object_{\mathrm{self}}.\;
      \bind(e_i,\; (\Class_{\mathrm{record}}, \Object_{\mathrm{self}}) :: \rho)\bigr]
    \]
    Each label gets a singleton list with one constructor.
    The constructor captures the scope chain $\rho$ and $\Class_{\mathrm{record}}$.

  \item \textbf{Composition:}
    $\bind(e_1 \oplus e_2,\; \rho) = \bind(e_1, \rho) \oplus \bind(e_2, \rho)$

  \item \textbf{Reference:}
    $\bind(\up^n.\ell_1.\ell_2\ldots\ell_k,\; \rho)$ with $k \ge 0$:

    Let $(\Class_n, \Object_n) = \rho(n)$, the $n$-th entry in the scope chain.
    \begin{align*}
      \text{if } k = 0 &: \quad \text{result} = \Class_n \\
      \text{if } k \ge 1 &: \quad
      (\Class_{\ell_1}, \Object_{\ell_1}) = \Object_n(\ell_1),\;\;
      \ldots,\;\;
      (\Class_{\ell_k}, \Object_{\ell_k}) = \Object_{\ell_{k-1}}(\ell_k) \\
      & \quad\;\; \text{result} = \Class_{\ell_k}
    \end{align*}
    Navigate through the $\Object$ chain by successive label projections,
    then return the $\Class$ at the final node.
    When $k = 0$, the reference inherits the entire enclosing scope's $\Class$,
    which may produce an infinitely deep tree.
    MixinCalculus does not prohibit infinite trees.
\end{itemize}

\section{Relationship to Other Computational Models}

\subsection{Translation from $\lambda$-Calculus}

The following translation maps $\lambda$-calculus with De Bruijn indices
to MixinCalculus.
Let $\mathcal{T}$ denote the translation function,
mapping a $\lambda$-term to a MixinCalculus expression $e$.

\medskip
\begin{center}
  \begin{tabular}{l@{\qquad$\longrightarrow$\qquad}l}
    $n$ (variable) & $\up^n.\mathrm{argument}$ \\
    $\lambda.\, e$ (abstraction) &
    $\{\mathrm{argument} \mapsto \{\},\; \mathrm{result} \mapsto \mathcal{T}(e)\}$ \\
    $e_1\; e_2$ (application) &
    $\mathcal{T}(e_1) \oplus \{\mathrm{argument} \mapsto \mathcal{T}(e_2)\}$
  \end{tabular}
\end{center}
\medskip

The result of an application is accessed via $.\mathrm{result}$.
Nested applications require ANF-style naming of intermediate results.

The translation from $\lambda$-calculus to MixinCalculus is straightforward.
The reverse direction is non-trivial, as we discuss next.

\subsection{Expressive Asymmetry}

The translation above consists of three simple rules. This simplicity
is significant: the full computational power of the $\lambda$-calculus
embeds into MixinCalculus with minimal overhead.

The reverse direction---encoding MixinCalculus in pure
$\lambda$-calculus---is established by the denotational semantics in Section~4.
However, this mapping is considerably more complex than its counterpart:
defining the meaning of MixinCalculus requires the full machinery of
fixed points, higher-order functions, and recursive domains. This sophistication is
not accidental---it reflects three features that have no direct
counterpart in the $\lambda$-calculus:

\begin{enumerate}
  \item \textbf{Self-referential fixed-point records.}
    The $\eval$ function constructs $\Object_{\mathrm{self}}$, which
    appears in its own definition. In the $\lambda$-calculus, encoding
    this requires explicit fixed-point combinators (e.g., the Y
    combinator) combined with records encoded as functions---a
    construction that obscures the declarative intent.

  \item \textbf{Open recursion with symmetric composition.}
    The operator $\oplus$ merges constructors from independent sources,
    all called with the same $\Object_{\mathrm{self}}$. Encoding this in
    the $\lambda$-calculus requires maintaining an extensible dictionary
    of methods that can be merged from multiple directions. Cook's
    denotational semantics of inheritance~\cite{cook1989denotational}
    devoted an entire dissertation to formalizing this pattern in a
    functional setting.

  \item \textbf{Commutative, idempotent merge.}
    Composition in MixinCalculus is symmetric:
    $e_1 \oplus e_2$ and $e_2 \oplus e_1$ produce the same observable
    result. In the $\lambda$-calculus, function composition
    $(f \circ g)$ is neither commutative nor idempotent, and simulating
    these properties requires additional machinery.
\end{enumerate}

\noindent
This asymmetry reveals that MixinCalculus is not simply the
$\lambda$-calculus in disguise. Rather, MixinCalculus provides
primitive operations for computational patterns that are
\emph{derivable but complex} in the $\lambda$-calculus.

\subsection{CPS-Agnostic Programs}

In the $\lambda$-calculus, a program is either in continuation-passing
style (CPS) or direct style. Converting between these representations
requires explicit transformation---the CPS
conversion~\cite{plotkin1975callbyname,sabry1993reasoning}.
MixinCalculus exhibits a different property: the same program text can
be interpreted as either CPS or direct-style depending on how
dependencies are assembled.

Consider a generic computation step:
\begin{align*}
  \mathrm{Step} \mapsto \{
    \mathrm{input} \mapsto \{\},\;
    \mathrm{process} \mapsto \{\},\;
    \mathrm{result} \mapsto \{\}
  \}
\end{align*}

The empty $\mathrm{process}$ slot is an \emph{interpretation point}. If
filled externally by an orchestrator, it acts as a continuation parameter
(CPS interpretation). If composed locally with an implementation, it acts
as a direct dependency (direct-style interpretation). The
$\mathrm{Step}$ code remains unchanged.

\paragraph{CPS interpretation via external orchestration.}
When $\mathrm{process}$ is injected from outside, the computation passes
its intermediate result to an external handler:
\begin{align*}
  &\mathrm{Step} \oplus \{ \\
    &\quad \mathrm{input} \mapsto \{\mathrm{data} \mapsto \{\}\},\; \\
    &\quad \mathrm{process} \mapsto \{ \\
      &\qquad \mathrm{result} \mapsto \{\mathrm{handled} \mapsto \{\}\} \\
    &\quad \} \\
  &\}
\end{align*}
The $\mathrm{process}$ slot acts as a continuation: it receives the
result and determines what happens next. This is CPS-style programming.

\paragraph{Direct-style interpretation via local composition.}
Alternatively, $\mathrm{process}$ can be filled by local composition:
\begin{align*}
  &\mathrm{Step} \oplus \{ \\
    &\quad \mathrm{input} \mapsto \{\mathrm{data} \mapsto \{\}\},\; \\
    &\quad \mathrm{process.result} \mapsto \{\mathrm{computed} \mapsto \{\}\} \\
  &\}
\end{align*}
Here $\mathrm{process}$ is implemented directly within the composition.
This is direct-style programming. The $\mathrm{Step}$ code is identical
in both cases---only the assembly strategy differs.

\paragraph{Representation independence.}
This property is a form of representation
independence~\cite{reynolds1983types} applied to control flow: client
code using $\mathrm{Step}$ need not know whether $\mathrm{process}$ will
be filled continuation-style or directly. Library authors write code
once; users choose the control flow style at assembly time.

The $\lambda$-calculus lacks this flexibility. A function written in
direct style must be explicitly transformed (CPS conversion) before it
can be used continuation-style. MixinCalculus programs are inherently in
A-normal form~\cite{flanagan1993essence}, where every intermediate result
has a name.

However, MixinCalculus ANF differs critically from ANF in functional
programming. In functional language compilers, ANF conversion requires
specifying a target monad---either a concrete monad or an abstract
one~\cite{moggi1991notions}. Compiler-internal ANF transformations (the
ANF form used in intermediate representations) typically target the
identity monad, which cannot express CPS transformations. This is
analogous to how imperative compilers use SSA (Static Single Assignment)
form, which similarly lacks control flow flexibility. MixinCalculus ANF,
by contrast, has built-in dependency injection: empty API slots can be
filled by external orchestrators. This capability enables the same ANF
program to serve both CPS and direct-style interpretations without monad
specification or transformation.

\paragraph{Multiple symmetric continuations.}
When interpreted continuation-style, MixinCalculus naturally supports
multiple exit points:
\begin{align*}
  \mathrm{Choice} \mapsto \{
    \mathrm{on\_success} &\mapsto \{\},\; \\
    \mathrm{on\_failure} &\mapsto \{\},\; \\
    \mathrm{on\_timeout} &\mapsto \{\},\; \\
    \mathrm{result} &\mapsto \{\}
  \}
\end{align*}

All continuation slots are symmetric under $\oplus$. Traditional CPS in
the $\lambda$-calculus distinguishes a single continuation parameter;
additional continuations must be encoded (e.g., as pairs or disjoint
sums). MixinCalculus treats all continuation slots uniformly, eliminating
the need for specialized encodings.

\paragraph{Abstract and concrete are syntactically identical.}
From a category-theoretic perspective, abstract algebra and concrete
implementation have the same syntactic structure in MixinCalculus:
\begin{align*}
  \text{Abstract:} \quad & \mathrm{API} \mapsto \{\} \\
  \text{Concrete:} \quad & \mathrm{API} \mapsto \{\text{implementation}\}
\end{align*}

This is the abstract/concrete correspondence: the same functor applies to
both. In traditional languages, abstract interfaces (e.g., Java
interfaces, Haskell type classes) have different syntax from concrete
implementations. In MixinCalculus, they are syntactically
identical---only the interpretation differs. An empty API is
simultaneously an abstract requirement (when viewed as a dependency) and
a concrete extension point (when viewed as an injection site).

The Selector and Rebuilder combinators (Appendix~\ref{app:trie})
demonstrate this flexibility: their callback slots
($\mathrm{on\_zero}$, $\mathrm{on\_odd}$, $\mathrm{on\_even}$) can be
filled externally (CPS interpretation) or composed locally (direct
interpretation).

\paragraph{Practical implications.}
This design enables flexible library interfaces. A library component with
empty API slots can be used in multiple contexts without modification:
\begin{itemize}
  \item In synchronous code, fill slots with direct implementations
  \item In asynchronous code, fill slots with continuation handlers
  \item In effect systems, compose with algebraic effect handlers~\cite{plotkin2003algebraic}
  \item In test code, fill slots with mock implementations
\end{itemize}

No dual APIs are needed. The same component serves all use cases. This
eliminates a common source of code duplication in traditional languages,
where async and sync versions of the same functionality must be
maintained separately.

\selfcite{The implementation~\cite{mixin2025} includes}{The supplementary material includes} executable examples of all three
patterns described above: escape continuations analogous to
\texttt{call/cc}, success/failure continuations analogous to exception
handling, and protected computations with multiple symmetric exit points.
Each example includes test cases verifying that the correct continuation
path is taken.

\subsection{Records as Tries: The RAM Machine Connection}
\label{sec:trie}

A record $\{\ell_1 \mapsto e_1,\; \ldots,\; \ell_n \mapsto e_n\}$ is
a trie node: each label selects a child subtree. Nested records form a
trie whose depth corresponds to key length. Composition ($\oplus$) is
natively trie union: merging two records combines their children
recursively. This observation yields an immutable analogue of
random-access memory.

The fundamental operations on random-access memory correspond directly
to MixinCalculus primitives:
\begin{itemize}
  \item \textbf{Write}: composing a singleton trie ($\oplus$).
  \item \textbf{Read (static)}: reference-path navigation
    ($\up^n.\ell_1.\ell_2\ldots\ell_k$).
  \item \textbf{Read (dynamic)}: folding a key into a Selector
    combinator that navigates the trie at runtime.
  \item \textbf{Delete}: folding a key into a Rebuilder combinator
    that reconstructs the trie, omitting the targeted entry.
  \item \textbf{Update}: composing deletion with insertion.
\end{itemize}

\noindent
In the $\lambda$-calculus, implementing a persistent trie with
efficient union requires explicit data structure encodings
(e.g., hash array mapped tries or finger trees). In MixinCalculus,
records \emph{are} tries and composition \emph{is} trie union---no
additional data structure is needed.
The full constructions (Selector, Rebuilder, Lookup, Delete, Update)
are given in Appendix~\ref{app:trie}.
\selfcite{The implementation~\cite{mixin2025} includes}{The supplementary material includes} executable implementations of all
trie operations---static and dynamic lookup, deletion, update, and trie
union---with test cases covering keys of varying bit structure.

\subsection{Contrast with SKI Combinator Calculus}

A natural question arises: is MixinCalculus merely another function-free
reformulation of the $\lambda$-calculus, analogous to the SKI combinator
calculus~\cite{schonfinkel1924,curry1958combinatory}?

Like MixinCalculus, the SKI combinator calculus is function-free at the
object level (no $\lambda$-abstractions), Turing complete, and minimal
(three combinators). However, SKI is \emph{isomorphic} to the
$\lambda$-calculus in terms of problem difficulty: the bracket
abstraction algorithm translates between the two systems while
preserving computational structure. Problems that are hard in the
$\lambda$-calculus---such as the Expression
Problem~(Section~\ref{sec:expression-problem})---remain equally hard
in SKI.

MixinCalculus, by contrast, exhibits a genuine shift in problem
difficulty. The Expression Problem, which requires sophisticated
encodings in $\lambda$-calculus-based systems---object
algebras~\cite{oliveira2012extensibility}, finally tagless
interpreters~\cite{carette2009finally}, or multi-parameter type
classes---becomes direct and natural in MixinCalculus via $\oplus$.
Similarly, random-access memory via immutable tries, which requires
explicit data structure engineering in the $\lambda$-calculus, is
simply the native record structure of MixinCalculus
(Section~\ref{sec:trie}). This difference in problem difficulty
demonstrates that MixinCalculus captures computational patterns that
are \emph{different} from those of the $\lambda$-calculus,
not merely syntactic variants.

\section{Discussion}

\subsection{Is MixinCalculus Just Functions in Disguise?}

A skeptical reader might observe that the semantic domain uses
$\Constructor = \Object \to \Class$, which is literally a function
type in the metalanguage. Does this mean MixinCalculus is simply
the $\lambda$-calculus with different syntax?

This objection confuses the object language with the metalanguage.
The semantic domain uses functions as a \emph{mathematical tool} to
define the meaning of MixinCalculus expressions, just as set theory is
used to define natural numbers without making arithmetic ``just set
theory in disguise.'' The crucial question is not what appears in the
denotational semantics, but what computational patterns are
\emph{primitive} in the language itself.

In MixinCalculus, the primitive operations are record construction,
reference, and composition. Function application is \emph{derived}
from these primitives (Section~5.1), not primitive itself.
Indeed, the asymmetry demonstrated in Section~5.2 makes this concrete:
embedding the $\lambda$-calculus into MixinCalculus requires only three
simple rules, while the reverse direction requires the sophisticated
machinery of Section~4. The real test of whether two computational
models are ``the same'' is whether they make the same problems easy
and the same problems hard. As shown in Section~5, they do not:

\begin{center}
  \begin{tabular}{lll}
    \textbf{System} & \textbf{Expression Problem} & \textbf{Random-access memory} \\
    \hline
    $\lambda$-calculus
    & Object algebras~\cite{oliveira2012extensibility},
    & Explicit trie encoding \\
    & finally tagless~\cite{carette2009finally} & \\
    SKI combinators
    & Same difficulty as $\lambda$
    & Same difficulty as $\lambda$ \\
    MixinCalculus
    & Direct composition ($\oplus$)
    & Records \emph{are} tries \\
  \end{tabular}
\end{center}

\noindent
The fact that MixinCalculus requires no additional machinery for either
problem class---while the $\lambda$-calculus requires elaborate
encodings for both---demonstrates that MixinCalculus captures
different computational primitives, not merely a
syntactic reshuffling.

\subsection{Properties of Composition}

Commutativity and idempotence of $\oplus$ make MixinCalculus
transparent to linearization order.
Deduplication of inherited mixins is purely an optimization.

\subsection{Implementation Considerations}

De Bruijn indices $\up^n$ are typically implemented as
qualified \textbf{self} references for readability.
Each scope level is given a name (e.g., $\mathrm{Succ}$),
and $\up^1.\mathrm{successor}$ is written as
$\mathrm{Succ}.\mathrm{successor}$,
where the name is resolved by walking up the scope chain.

\subsection{Relationship to Practical Systems}

MixinCalculus provides a theoretical foundation for understanding several
classes of declarative systems that have emerged independently in practice.

\paragraph{Configuration languages.}
The NixOS module system~\cite{dolstra2008nixos,nixosmodules}---whose
recursive attribute merging motivated this work---can be understood as an
implementation of MixinCalculus with additional features (type checking,
error reporting, FFI to the Nix language). The module system's
expressiveness stems from the properties described in Section~4: composition
is commutative, idempotent, and associative, so the linearization
problem does not arise. Other configuration languages exhibit similar patterns:
Jsonnet~\cite{jsonnet} provides inheritance-based composition over JSON;
CUE~\cite{cue2019} unifies types and values through lattice-based merging;
Dhall~\cite{dhall2017} combines functional programming with configuration.
All share MixinCalculus's core pattern: composition over recursive
structures without explicit functions.

\paragraph{Mixin-based object systems.}
Scala traits~\cite{odersky2004overview}, Ruby mixins~\cite{flanagan2008ruby},
and similar object-oriented mechanisms use symmetric composition to extend
classes. Traditional mixin calculi~\cite{bracha1990mixin,scharli2003traits}
face the linearization problem when composing mixins with conflicting
fields. In MixinCalculus, this problem does not arise (Section~4) because eliminating
scalar values: only key presence is observable, making composition
naturally commutative. This explains why trait systems with
conflict-resolution strategies (e.g., Scala's linearization) require
additional machinery that MixinCalculus does not.

\paragraph{Effect systems.}
Algebraic effects with handlers~\cite{plotkin2003algebraic,pretnar2015introduction}
and monad transformers structure computational effects through composition.
The CPS-agnostic property (Section~5.3) shows how MixinCalculus naturally
supports effect handler composition: empty API slots can be filled with
effect handlers (CPS interpretation) or direct implementations (direct-style
interpretation). This correspondence suggests that MixinCalculus may provide
a foundation for understanding effect systems without requiring explicit
monad machinery.

\paragraph{Modular software architectures.}
Plugin systems, component frameworks, and dependency injection frameworks
enable software extensibility through declarative composition. The
symmetric, associative nature of $\oplus$ (Section~4) explains why such
systems work: components can be composed in any order without changing
behavior. MixinCalculus formalizes the composition patterns that these
systems implement ad hoc.

\paragraph{Union file systems.}
Union file systems (UnionFS, OverlayFS, AUFS) layer multiple directory
hierarchies to present a unified view. The composition semantics directly
mirror MixinCalculus: later layers override earlier layers (asymmetric
composition), files from all layers remain accessible (non-destructive
merging), and composition order affects conflict resolution (non-commutative
when scalar files conflict). A proof-of-concept
\selfcite{implementation~\cite{ratarmount2025} (included as supplementary material)}{implementation (included as supplementary material)}
demonstrates that MixinCalculus
patterns emerge naturally in union mount composition through late-binding
semantics and dynamic dispatch for file lookups across layers.

\section{Future Work}

\paragraph{Typed Mixin Calculus.}
MixinCalculus as presented here is untyped. A natural next step is to
develop a \emph{Typed Mixin Calculus} (TMC) that adds a type system
while preserving the declarative character of the calculus.
The key observation is that type systems are themselves a form of
declarative programming: one declares types to guide meta-computation
(type checking, type inference) without specifying operational steps.
Since MixinCalculus demonstrates that declarative programming can be
Turing complete, applying this insight to the type level yields a type
system built from the same mixin primitives.
TMC would relate to the DOT calculus~\cite{amin2016dot} in a manner
analogous to how MixinCalculus relates to the $\lambda$-calculus:
TMC can be viewed as DOT without $\lambda$, retaining
path-dependent types while replacing functions with inheritance-based
composition.

A key difference concerns the interpretation of structural annotations.
In untyped MixinCalculus, writing $\mathrm{magnitude} \mapsto \{\}$ in
a schema (as in the informal example of Section~1) is purely
documentary---it defines a structural slot but imposes no constraint.
The expression $\mathrm{outcome} \mapsto \up^0.\mathrm{magnitude}$
succeeds as long as $\mathrm{magnitude}$ exists somewhere in the
composition chain, regardless of any schema declaration.
TMC would enforce such annotations statically, rejecting programs at
compile time where the declared structure does not match the actual
composition.
Such a typed system would be amenable to mechanization in proof
assistants (Coq, Agda) for verifying type safety, progress, and
preservation properties.

\bibliographystyle{ACM-Reference-Format}
\bibliography{mixin-calculus}

\appendix

\section{Trie Operations}
\label{app:trie}

This appendix gives the full constructions for the RAM machine
operations summarized in Section~\ref{sec:trie}.
Index the trie by binary natural numbers using three labels---$\mathrm{value}$
for the stored entry at a node, $\mathrm{at\_odd}$ and $\mathrm{at\_even}$
for the two children corresponding to the bit structure of the key:
\begin{align*}
  \mathrm{Zero} &\;\longrightarrow\; \mathrm{value} \\
  \mathrm{Odd}(n) &\;\longrightarrow\; \mathrm{at\_odd},\;\text{then path for } n \\
  \mathrm{Even}(n) &\;\longrightarrow\; \mathrm{at\_even},\;\text{then path for } n
\end{align*}

\paragraph{Write (insertion).}
Inserting an entry with value $v$ at key $k$ is composing a singleton
trie whose nesting mirrors the bit structure of $k$.
For example, inserting at key $5 = \mathrm{Odd}(\mathrm{Even}(\mathrm{Zero}))$:
\[
  \mathrm{trie}' = \mathrm{trie} \oplus
  \{\mathrm{at\_odd} \mapsto \{\mathrm{at\_even} \mapsto \{\mathrm{value} \mapsto v\}\}\}
\]
Each composition creates a new immutable trie; the original is unchanged.

\paragraph{Read (static lookup).}
When the key is known statically, retrieving the entry at key $k$ is
reference-path navigation: the reference follows the same label
sequence that was used for insertion. For the same key~$5$:
\[
  \up^n.\mathrm{trie}.\mathrm{at\_odd}.\mathrm{at\_even}.\mathrm{value}
\]
where $n$ is the appropriate De~Bruijn index.
The reference mechanism traverses the nested record structure---which
\emph{is} the trie---returning the $\Class$ at the final node.

\paragraph{Read (dynamic lookup).}
When the key is a BinNat value constructed at runtime via
$\mathrm{Zero}$, $\mathrm{Odd}$, and $\mathrm{Even}$, the lookup
path must be computed dynamically. This is achieved by folding the
BinNat key into a \emph{Selector}---a mixin that, given a trie,
navigates to the appropriate node and returns the stored entry.
A Selector declares the trie shape and a result slot:
\[
  \mathrm{Selector} \mapsto \{
    \mathrm{trie} \mapsto \{
      \mathrm{value} \mapsto \{\},\;
      \mathrm{at\_odd} \mapsto \{\},\;
    \mathrm{at\_even} \mapsto \{\}\},\;
  \mathrm{result} \mapsto \{\}\}
\]
Three observer callbacks build Selectors bottom-up. These callbacks
($\mathrm{on\_zero}$, $\mathrm{on\_odd}$, $\mathrm{on\_even}$) are
interpretation points in the sense of Section~5.3: they can be filled
externally by an orchestrator (CPS interpretation) or composed locally
(direct interpretation), demonstrating the CPS-agnostic property.
The $\mathrm{on\_zero}$ callback returns a Selector that reads
$.\mathrm{value}$ from the trie:
\[
  \mathrm{lookup\_on\_zero} \mapsto \up^0.\mathrm{Selector} \oplus
  \{\mathrm{result} \mapsto \up^0.\mathrm{trie}.\mathrm{value}\}
\]
The $\mathrm{on\_odd}$ callback takes a Selector
(via the $\mathrm{argument}/\mathrm{result}$ encoding of
Section~5.1) and returns a new Selector that navigates to
$.\mathrm{at\_odd}$, then delegates to the argument Selector:
\begin{align*}
  \mathrm{lookup\_on\_odd} &\mapsto \{
    \mathrm{argument} \mapsto \up^1.\mathrm{Selector},\;
    \mathrm{result} \mapsto \up^1.\mathrm{Selector} \oplus \{\\
      &\qquad
      \mathrm{applied} \mapsto \up^1.\mathrm{argument} \oplus
      \{\mathrm{trie} \mapsto \up^1.\mathrm{trie}.\mathrm{at\_odd}\},\\
      &\qquad
  \mathrm{result} \mapsto \up^0.\mathrm{applied}.\mathrm{result}\}\}
\end{align*}
The $\mathrm{on\_even}$ callback is symmetric, navigating to
$.\mathrm{at\_even}$ instead.

The $\mathrm{Lookup}$ combinator folds a BinNat key with these
callbacks to obtain a Selector, then applies it to the trie:
\begin{align*}
  \mathrm{Lookup} &\mapsto \{\\
    &\quad \mathrm{key} \mapsto \up^1.\mathrm{BinNat},\\
    &\quad \mathrm{trie\_input} \mapsto \{\},\\
    &\quad \mathrm{applied\_key} \mapsto \up^0.\mathrm{key} \oplus \{
      \mathrm{on\_zero} \mapsto \up^1.\mathrm{lookup\_on\_zero},\;
      \mathrm{on\_odd} \mapsto \up^1.\mathrm{lookup\_on\_odd},\;
    \mathrm{on\_even} \mapsto \up^1.\mathrm{lookup\_on\_even}\},\\
    &\quad \mathrm{applied\_selector} \mapsto
    \up^0.\mathrm{applied\_key}.\mathrm{result} \oplus
    \{\mathrm{trie} \mapsto \up^1.\mathrm{trie\_input}\},\\
  &\quad \mathrm{result} \mapsto \up^0.\mathrm{applied\_selector}.\mathrm{result}\}
\end{align*}
For example, looking up key $5 = \mathrm{Odd}(\mathrm{Even}(\mathrm{Zero}))$
folds into a Selector that navigates
$.\mathrm{at\_odd}.\mathrm{at\_even}.\mathrm{value}$---the same path
as the static reference, but computed from the key value.
The entire construction uses only composition ($\oplus$) and
references; no additional primitives are needed.

\paragraph{Delete.}
Since composition is additive---it can only merge properties, never
remove them---deletion cannot be expressed as a single composition.
Instead, deletion \emph{reconstructs} the trie, copying every subtrie
except at the targeted key.

We fold the BinNat key into a \emph{Rebuilder}---a mixin that, given
an input trie, produces a new trie as its result.
A Rebuilder declares the trie shape on both its input and output:
\[
  \mathrm{Rebuilder} \mapsto \{
    \mathrm{trie} \mapsto \{\mathrm{value}, \mathrm{at\_odd}, \mathrm{at\_even}\},\;
  \mathrm{result} \mapsto \{\mathrm{value}, \mathrm{at\_odd}, \mathrm{at\_even}\}\}
\]
Three observer callbacks build Rebuilders bottom-up.
The $\mathrm{on\_zero}$ callback returns a Rebuilder that copies the
subtries but omits the value:
\[
  \mathrm{delete\_on\_zero} \mapsto \up^0.\mathrm{Rebuilder} \oplus
  \{\mathrm{result} \mapsto \{
      \mathrm{at\_odd} \mapsto \up^1.\mathrm{trie}.\mathrm{at\_odd},\;
  \mathrm{at\_even} \mapsto \up^1.\mathrm{trie}.\mathrm{at\_even}\}\}
\]
The $\mathrm{result}.\mathrm{value}$ slot inherits only the empty
declaration from $\mathrm{Rebuilder}$, effectively deleting the entry.

The $\mathrm{on\_odd}$ callback takes a Rebuilder (the recursive
result for the subtrie) and returns a new Rebuilder that preserves
$\mathrm{value}$ and $\mathrm{at\_even}$, but replaces
$\mathrm{at\_odd}$ with the recursively rebuilt subtrie:
\begin{align*}
  \mathrm{delete\_on\_odd} &\mapsto \{
    \mathrm{argument} \mapsto \up^1.\mathrm{Rebuilder},\;
    \mathrm{result} \mapsto \up^1.\mathrm{Rebuilder} \oplus \{\\
      &\qquad
      \mathrm{applied} \mapsto \up^1.\mathrm{argument} \oplus
      \{\mathrm{trie} \mapsto \up^1.\mathrm{trie}.\mathrm{at\_odd}\},\\
      &\qquad
      \mathrm{result} \mapsto \{
        \mathrm{value} \mapsto \up^2.\mathrm{trie}.\mathrm{value},\;
        \mathrm{at\_odd} \mapsto \up^0.\mathrm{applied}.\mathrm{result},\;
        \mathrm{at\_even} \mapsto \up^2.\mathrm{trie}.\mathrm{at\_even}
  \}\}\}
\end{align*}
The $\mathrm{on\_even}$ callback is symmetric.

The $\mathrm{Delete}$ combinator folds a BinNat key with these
callbacks to obtain a Rebuilder, then applies it to the trie:
\begin{align*}
  \mathrm{Delete} &\mapsto \{\\
    &\quad \mathrm{key} \mapsto \up^1.\mathrm{BinNat},\\
    &\quad \mathrm{trie\_input} \mapsto \{\},\\
    &\quad \mathrm{applied\_key} \mapsto \up^0.\mathrm{key} \oplus \{
      \mathrm{on\_zero} \mapsto \up^1.\mathrm{delete\_on\_zero},\;
      \mathrm{on\_odd} \mapsto \up^1.\mathrm{delete\_on\_odd},\;
    \mathrm{on\_even} \mapsto \up^1.\mathrm{delete\_on\_even}\},\\
    &\quad \mathrm{applied\_rebuilder} \mapsto
    \up^0.\mathrm{applied\_key}.\mathrm{result} \oplus
    \{\mathrm{trie} \mapsto \up^1.\mathrm{trie\_input}\},\\
  &\quad \mathrm{result} \mapsto \up^0.\mathrm{applied\_rebuilder}.\mathrm{result}\}
\end{align*}
Since composition is idempotent, the empty scaffolding left by the
Rebuilder schema merges harmlessly with any subsequent insertions.

\paragraph{Update.}
Updating the entry at key $k$ to a new value $v$ combines deletion
and insertion.  Because $\mathrm{Delete}$ is a combinator whose
output lives in the \emph{result} property, one must first project
out the rebuilt trie before composing with the new singleton.
In ANF style:
\begin{align*}
  \mathrm{deleted} &\mapsto \up^n.\mathrm{Delete} \oplus \{
    \mathrm{key} \mapsto k,\;
  \mathrm{trie\_input} \mapsto \mathrm{trie}\}\\
  \mathrm{result} &\mapsto \up^0.\mathrm{deleted}.\mathrm{result} \oplus
  \{\mathrm{at\_odd} \mapsto \{\mathrm{at\_even} \mapsto
  \{\mathrm{value} \mapsto v\}\}\}
\end{align*}
where the second line uses key $5 = \mathrm{Odd}(\mathrm{Even}(\mathrm{Zero}))$
as a concrete example.
The projection $.\mathrm{result}$ is essential: $\mathrm{Delete}$
carries internal scaffolding ($\mathrm{key}$, $\mathrm{trie\_input}$,
$\mathrm{applied\_key}$, etc.), and only its $\mathrm{result}$
property holds the rebuilt trie.  This intermediate projection
prevents Update from being a single symmetric composition.

\section{Church Encoding of Standard Types}
\label{app:church}

This appendix demonstrates that standard data types can be encoded in
MixinCalculus without scalar types, using Church encoding. These
encodings serve as a proof of concept that a standard library can be
built entirely within MixinCalculus. Each encoding is presented as a
module mixin. In practical implementations, more efficient
representations (e.g., binary naturals) or FFI to host language
primitives would typically be used.
\selfcite{The implementation~\cite{mixin2025} includes}{The supplementary material includes} executable implementations of these
encodings with test cases for $\mathrm{Not}(\mathrm{True})$,
$\mathrm{And}(\mathrm{True}, \mathrm{True})$,
$\mathrm{Or}(\mathrm{False}, \mathrm{True})$, and natural number
addition, all verified against expected output snapshots.

\subsection{Boolean Module}

The boolean module contains a schema ($\mathrm{Boolean}$), constructors
($\mathrm{True}$, $\mathrm{False}$), and operations ($\mathrm{Not}$,
$\mathrm{And}$, $\mathrm{Or}$). All definitions are siblings within a
single module mixin; references use De~Bruijn indices accordingly.

\begin{align*}
  \{ \quad \mathrm{boolean} \mapsto \{ \quad
      \mathrm{Boolean} &\mapsto \{\mathrm{on\_true} \mapsto \{\},\;
        \mathrm{on\_false} \mapsto \{\},\;
      \mathrm{result} \mapsto \{\}\},
      \\[6pt]
      \mathrm{True} &\mapsto \up^0.\mathrm{Boolean} \oplus
      \{\mathrm{result} \mapsto \up^0.\mathrm{on\_true}\},
      \\
      \mathrm{False} &\mapsto \up^0.\mathrm{Boolean} \oplus
      \{\mathrm{result} \mapsto \up^0.\mathrm{on\_false}\},
      \\[6pt]
      \mathrm{Not} &\mapsto \up^0.\mathrm{Boolean} \oplus \{\\
        &\qquad \mathrm{operand} \mapsto \up^1.\mathrm{Boolean},\\
        &\qquad \mathrm{applied\_operand} \mapsto \up^0.\mathrm{operand} \oplus \{\\
          &\qquad\qquad \mathrm{on\_true} \mapsto \up^1.\mathrm{on\_false},\\
        &\qquad\qquad \mathrm{on\_false} \mapsto \up^1.\mathrm{on\_true}\},\\
      &\qquad \mathrm{result} \mapsto \up^0.\mathrm{applied\_operand}.\mathrm{result}\},
      \\[6pt]
      \mathrm{And} &\mapsto \up^0.\mathrm{Boolean} \oplus \{\\
        &\qquad \mathrm{left} \mapsto \up^1.\mathrm{Boolean},\\
        &\qquad \mathrm{right} \mapsto \up^1.\mathrm{Boolean},\\
        &\qquad \mathrm{applied\_left} \mapsto \up^0.\mathrm{left} \oplus \{\\
          &\qquad\qquad \mathrm{on\_true} \mapsto \up^1.\mathrm{right},\\
        &\qquad\qquad \mathrm{on\_false} \mapsto \up^2.\mathrm{False}\},\\
      &\qquad \mathrm{result} \mapsto \up^0.\mathrm{applied\_left}.\mathrm{result}\},
      \\[6pt]
      \mathrm{Or} &\mapsto \up^0.\mathrm{Boolean} \oplus \{\\
        &\qquad \mathrm{left} \mapsto \up^1.\mathrm{Boolean},\\
        &\qquad \mathrm{right} \mapsto \up^1.\mathrm{Boolean},\\
        &\qquad \mathrm{applied\_left} \mapsto \up^0.\mathrm{left} \oplus \{\\
          &\qquad\qquad \mathrm{on\_true} \mapsto \up^2.\mathrm{True},\\
        &\qquad\qquad \mathrm{on\_false} \mapsto \up^1.\mathrm{right}\},\\
      &\qquad \mathrm{result} \mapsto \up^0.\mathrm{applied\_left}.\mathrm{result}\}
  \quad \} \quad \}
\end{align*}

\paragraph{De Bruijn index explanation.}
Within the $\mathrm{boolean}$ module:
\begin{itemize}
  \item At the top level of the module $\{\ldots\}$:
    $\up^0$ refers to $\{\mathrm{Boolean}, \mathrm{True}, \mathrm{False},
    \mathrm{Not}, \mathrm{And}, \mathrm{Or}\}$.
  \item Inside True's $\{\mathrm{result} \mapsto \ldots\}$:
    $\up^0$ refers to True's properties after merge with Boolean
    (including $\mathrm{result}$, $\mathrm{on\_true}$, $\mathrm{on\_false}$).
    $\up^1$ refers to the module scope.
  \item Inside Not's $\{\mathrm{operand},\; \mathrm{applied\_operand},\; \mathrm{result},\; \ldots\}$:
    $\up^0$ refers to Not's properties after merge.
    $\up^1$ refers to the module scope.
  \item Inside $\{\mathrm{on\_true},\; \mathrm{on\_false}\}$ nested in Not:
    $\up^0$ refers to the inner record's properties.
    $\up^1$ refers to Not's scope.
    $\up^2$ refers to the module scope.
\end{itemize}

\paragraph{Worked example.}
Consider the expression
$\up^0.\mathrm{boolean}.\mathrm{Not} \oplus \{\mathrm{operand} \mapsto \up^1.\mathrm{boolean}.\mathrm{True}\}
\oplus \{\mathrm{on\_true} \mapsto A,\; \mathrm{on\_false} \mapsto B\}$
at the root scope level,
where $A$ and $B$ are arbitrary expressions.
The result is an object whose $\mathrm{result}$ key contains the same observable tree as $B$,
because $\mathrm{Not}$ swaps $\mathrm{on\_true}$ and $\mathrm{on\_false}$,
and $\mathrm{True}$ selects $\mathrm{on\_true}$,
which after swapping becomes $B$.

\subsection{Natural Number Module}

The natural number module contains a schema ($\mathrm{Nat}$),
constructors ($\mathrm{Zero}$, $\mathrm{Succ}$), and an operation
($\mathrm{Add}$).

\begin{align*}
  \{ \quad \mathrm{natural} \mapsto \{ \quad
      \mathrm{Nat} &\mapsto \{\mathrm{successor} \mapsto \{\mathrm{argument} \mapsto \{\},\;
        \mathrm{result} \mapsto \{\}\},\;
        \mathrm{zero} \mapsto \{\},\;
      \mathrm{result} \mapsto \{\}\},
      \\[6pt]
      \mathrm{Zero} &\mapsto \up^0.\mathrm{Nat} \oplus
      \{\mathrm{result} \mapsto \up^0.\mathrm{zero}\},
      \\[6pt]
      \mathrm{Succ} &\mapsto \up^0.\mathrm{Nat} \oplus \{\\
        &\qquad \mathrm{predecessor} \mapsto \up^1.\mathrm{Nat},\\
        &\qquad \mathrm{applied\_predecessor} \mapsto \up^0.\mathrm{predecessor} \oplus \{\\
          &\qquad\qquad \mathrm{successor} \mapsto \up^1.\mathrm{successor},\\
        &\qquad\qquad \mathrm{zero} \mapsto \up^1.\mathrm{zero}\},\\
        &\qquad \mathrm{applied\_successor} \mapsto \up^0.\mathrm{successor} \oplus \{\\
        &\qquad\qquad \mathrm{argument} \mapsto \up^1.\mathrm{applied\_predecessor}.\mathrm{result}\},\\
      &\qquad \mathrm{result} \mapsto \up^0.\mathrm{applied\_successor}.\mathrm{result}\},
      \\[6pt]
      \mathrm{Add} &\mapsto \up^0.\mathrm{Nat} \oplus \{\\
        &\qquad \mathrm{augend} \mapsto \up^1.\mathrm{Nat},\\
        &\qquad \mathrm{addend} \mapsto \up^1.\mathrm{Nat},\\
        &\qquad \mathrm{applied\_addend} \mapsto \up^0.\mathrm{addend} \oplus \{\\
          &\qquad\qquad \mathrm{successor} \mapsto \up^1.\mathrm{successor},\\
        &\qquad\qquad \mathrm{zero} \mapsto \up^1.\mathrm{zero}\},\\
        &\qquad \mathrm{applied\_augend} \mapsto \up^0.\mathrm{augend} \oplus \{\\
          &\qquad\qquad \mathrm{successor} \mapsto \up^1.\mathrm{successor},\\
        &\qquad\qquad \mathrm{zero} \mapsto \up^1.\mathrm{applied\_addend}.\mathrm{result}\},\\
      &\qquad \mathrm{result} \mapsto \up^0.\mathrm{applied\_augend}.\mathrm{result}\}
  \quad \} \quad \}
\end{align*}

\paragraph{Concrete example.}
At the root scope level,
$\mathrm{one} \mapsto \up^0.\mathrm{natural}.\mathrm{Succ} \oplus \{\mathrm{predecessor} \mapsto \up^1.\mathrm{natural}.\mathrm{Zero}\}$.
Applying this with a Peano-style successor and zero:
$\up^0.\mathrm{one} \oplus \{\mathrm{successor} \mapsto S,\; \mathrm{zero} \mapsto Z\}$
produces an object whose $\mathrm{result}$ key contains the same observable tree as
$S \oplus \{\mathrm{argument} \mapsto Z.\mathrm{result}\}.\mathrm{result}$,
i.e., successor applied once to zero.
Here $S$ and $Z$ are arbitrary expressions representing
a successor operation and a zero value respectively.

\end{document}
